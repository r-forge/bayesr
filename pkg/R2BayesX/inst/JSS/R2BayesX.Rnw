\documentclass[nojss]{jss}
% \documentclass[article]{jss}
\usepackage{amsmath,amssymb,amsfonts,thumbpdf}
\usepackage{multirow,longtable}

%% additional commands
\newcommand{\squote}[1]{`{#1}'}
\newcommand{\dquote}[1]{``{#1}''}
\newcommand{\fct}[1]{{\texttt{#1()}\index{#1@\texttt{#1()}}}}
\newcommand{\class}[1]{\dquote{\texttt{#1}}}
%% for internal use
\newcommand{\fixme}[1]{\emph{\marginpar{FIXME} (#1)}}
\newcommand{\readme}[1]{\emph{\marginpar{README} (#1)}}

%% Authors: NU + rest in alphabetical order
\author{Nikolaus Umlauf\\Universit\"at Innsbruck \And
        Daniel Adler\\Universit\"at G\"ottingen \And
        Thomas Kneib\\Universit\"at G\"ottingen \AND
        Stefan Lang\\Universit\"at Innsbruck \And
        Achim Zeileis\\Universit\"at Innsbruck}
\Plainauthor{Nikolaus Umlauf, Daniel Adler, Thomas Kneib, Stefan Lang, Achim Zeileis}

\title{Structured Additive Regression Models: An \proglang{R} Interface to \pkg{BayesX}}
\Plaintitle{Structured Additive Regression Models: An R Interface to BayesX}

\Keywords{STAR models, MCMC, REML, stepwise, \proglang{R}}
\Plainkeywords{STAR models, MCMC, REML, stepwise, R}

\Abstract{
Structured additive regression (STAR) models provide a flexible framework for modeling possible
nonlinear effects of covariates: They contain the well established frameworks of generalized linear
models (GLM) and generalized additive models (GAM) as special cases but also allow a wider class of
effects, e.g., for geographical or spatio-temporal data, allowing for specification of complex and 
realistic models. \pkg{BayesX} is standalone software package providing software for fitting general
class of STAR models. Based on a comprehensive open-source regression toolbox written in \proglang{C++},
\pkg{BayesX} uses Bayesian inference for estimating STAR models based on either modern Markov chain Monte 
Carlo (MCMC) simulation techniques, or based on a mixed model representation of STAR models, or with 
stepwise regression techniques combining penalized least squares estimation with model selection.
\pkg{BayesX} not only covers models for responses from univariate exponential families, but also models from less-standard
regression situations such as models for multi-categorical responses with either ordered or 
unordered categories, continuous time survival data, or continuous time multi-state models. This
paper presents a new fully interactive \proglang{R} interface to \pkg{BayesX}: the \proglang{R} package
\pkg{R2BayesX}. With the new package, STAR models can be conveniently specified using \proglang{R}'s formula language (with
some extended terms), fitted using the \pkg{BayesX} binary, represented in \proglang{R} with objects
of suitable classes, and finally printed/summarized/plotted. This makes \pkg{BayesX} much more
accessible to users familiar with \proglang{R} and adds extensive graphics capabilities for
visualizing fitted STAR models. Furthermore, \pkg{R2BayesX} complements the already impressive
capabilities for semiparametric regression in \proglang{R} by a comprehensive toolbox for
simulation-based Bayesian inference in such models, also covering models for multivariate responses.
}

\Address{
  Nikolaus Umlauf, Stefan Lang, Achim Zeileis\\
  Department of Statistics\\
  Faculty of Economics and Statistics\\
  Universit\"at Innsbruck\\
  Universit\"atsstr.~15\\
  6020 Innsbruck, Austria\\
  E-mail: \email{Nikolaus.Umlauf@uibk.ac.at},\\
  \phantom{E-mail: }\email{Stefan.Lang@uibk.ac.at},\\
  \phantom{E-mail: }\email{Achim.Zeileis@R-project.org}\\
  URL: \url{http://eeecon.uibk.ac.at/~umlauf/},\\
  \phantom{URL: }\url{http://www.uibk.ac.at/statistics/personal/lang/},\\
  \phantom{URL: }\url{http://eeecon.uibk.ac.at/~zeileis/}\\

  Thomas Kneib, Daniel Adler\\
  Department of Statistics and Econometrics\\
  Georg-August-Universit\"at G\"ottingen\\
  Platz der G\"ottinger Sieben 5 (MZG)\\
  37073 G\"ottingen, Germany \\
  E-mail: \email{tkneib@uni-goettingen.de}\\
  \phantom{E-mail: }\email{dadler@uni-goettingen.de},\\
  URL: \url{http://www.uni-goettingen.de/en/264255.html},\\
  \phantom{URL: }\url{http://neoscientists.org/~dadler/}\\
}

%% Sweave/vignette information and metadata
%% need no \usepackage{Sweave}
\SweaveOpts{engine = R, eps = FALSE, keep.source = TRUE}
%\VignetteIndexEntry{Structured Additive Regression Models: An R Interface to BayesX}
%\VignetteDepends{colorspace,mgcv,BayesX,akima}
%\VignetteKeywords{STAR models, MCMC, REML, stepwise, R}
%\VignettePackage{R2BayesX}

<<preliminaries, echo=FALSE, results=hide>>=
options(width = 70, prompt = "R> ", continue = "+  ")
library("R2BayesX")
data("ZambiaBnd")
data("BeechBnd")
@


\begin{document}


\section{Introduction} \label{sec:intro}

The free software \pkg{BayesX} \citep[see][]{R2BayesX:Brezger+Kneib+Lang:2005} is a standalone program
\citep[current version~2.0.1,][]{R2BayesX:Belitz+Brezger+Kneib+Lang:2011}
comprising powerful tools for Bayesian and mixed-model-based inference in complex semiparametric
regression models with structured additive predictor. Besides exponential
family regression, \pkg{BayesX} also supports models for multi-categorical responses, hazard
regression for continuous survival times, and continuous time multi-state models. The software
is written in \proglang{C++}, utilizing numerically efficient (sparse) matrix architectures. 

To facilitate usage of results from \pkg{BayesX} in subsequent analyses, specifically
in explorations and visualizations of the fitted models, \cite{R2BayesX:Kneib+Heinzl+Brezger:2011}
provide a package for \proglang{R} \citep{R2BayesX:R}, also called \pkg{BayesX}, that can
read and process output files from \pkg{BayesX}. However, in this approach the users still have
to read their data into \pkg{BayesX}, fit the models of interest and obtain the corresponding
output files. To alleviate this task, we introduce a new \proglang{R} package \pkg{R2BayesX}
that provides a fully interactive \proglang{R} interface to \pkg{BayesX} that has the usual
\proglang{R} modeling ``look \& feel'' and obviates the tedious exercise of manually exporting data
and fitting models in \pkg{BayesX}. Within the new package, users are now provided with 
the typical \proglang{R} modeling workflow namely:
%
\begin{itemize}
  \item Specification and estimation of STAR models using \code{bayesx(formula, data, ...)}
        (which internally calls \pkg{BayesX} and reads its results).
  \item Methods and extractor functions for fitted \class{bayesx} model objects, e.g., 
        producing high-level graphics of estimated effects, model diagnostic plots, summary statistics etc.
\end{itemize}
%
In addition, users can leverage the underlying infrastructure, i.e.:
%
\begin{itemize}
  \item Run already existing \pkg{BayesX} input program files from \proglang{R} via
        \fct{run.bayesx}.
  \item Automatically import \pkg{BayesX} output files into \proglang{R} via
        \fct{read.bayesx.output}.
\end{itemize}
%
The formula interface of the \fct{bayesx} function uses several special model term
constructor functions for the structured predictors: \fct{sx} and \fct{r} for smooth and random effects,
respectively, as well as the functions \fct{s} and \fct{te} from the \pkg{mgcv} package
\citep{R2BayesX:Wood:2011, R2BayesX:Wood:2006}, facilitating a consistent way to translate
\proglang{R} syntax into \pkg{BayesX}-interpretable commands.

The functionality is made available in package \pkg{R2BayesX}, available from the Comprehensive
\proglang{R} Archive Network (CRAN) at \url{http://CRAN.R-project.org/package=R2BayesX}. It depends
on the companion package \pkg{BayesXsrc} \citep[also available from CRAN, see][]{R2BayesX:Adler+Lang+Kneib:2012}
that ships the \pkg{BayesX} \proglang{C++} sources along with flexible \code{Makefile}s so that upon
installation of the \proglang{R} package a suitable \pkg{BayesX} binary is produced on all platforms.

The remainder of this paper is as follows. Section~\ref{sec:motivation} gives a first motivating example of an
\proglang{R} session applying \pkg{R2BayesX} to a dataset on childhood malnutrition in Zambia.
Subsequently, Section~\ref{sec:model} briefly discusses the methodological background of structured additive
regression models before Section~\ref{sec:implementation} describes the implementation details and the user interface
provided by \pkg{R2BayesX}. In Section~\ref{sec:illustrations}, the versatility of \pkg{BayesX} 
and the flexibility of the \pkg{R2BayesX} interface are further illustrated with
an extended analyses of the childhood malnutrition data and a dataset on forest health in Germany.


\section{Motivating example} \label{sec:motivation}

To give an introductory example of the various features of the interface, we estimate a Bayesian
geoadditive regression model for the childhood malnutrition dataset in Zambia (see
\citealp{R2BayesX:Kandala+Lang+Klasen+Fahrmeir:2001} and also Section~\ref{subsec:zambia}) using Markov
chain Monte Carlo (MCMC) simulation. 

The data consists of 4847 observations including 8 variables, both continuous and categorical. In
this analysis, the main interest is assessment of the determinats of stunting (\code{stunting}),
represented by anthropometric indicators of newborn children. Covariates include the age of the
children (\code{agechild}), the body mass index (BMI) of the mother (\code{mbmi}) and the district the children live
in (\code{district}). The model is given by
\begin{equation*}
\texttt{stunting}_i = \gamma_0 + f_1(\texttt{agechild}_i) + f_2(\texttt{mbmi}_i) +
  f_{spat}(\texttt{district}_i) + \varepsilon_i, \qquad \varepsilon_i \sim N(0, \sigma^2),
\end{equation*}
where the functions $f_1$ and $f_2$ of continuous covariates \code{agechild} and \code{mbmi} have
possible nonlinear effects on \code{stunting} and are  modeled nonparametrically using
P(enalized)-splines. Here, the spatially correlated effect $f_{spat}$ of locational covariate
\code{district} is modeled using kriging based on centroid coordinates (geokriging) of the districts
in Zambia. To estimate the model with \pkg{BayesX} from \proglang{R}, the data together with a
map of the districts in Zambia (see Section~\ref{subsec:addterms} for details of the map format)
is loaded with
<<data-illustration, echo=TRUE, eval=TRUE, fig=FALSE>>=
data("ZambiaNutrition", "ZambiaBnd", package = "R2BayesX")
@
The model formula is specified by
<<formula-illustration, echo=TRUE, eval=TRUE, fig=FALSE>>=
f <- stunting ~ sx(agechild) + sx(mbmi) +
  sx(district, bs = "gk", map = ZambiaBnd, full = TRUE)
@
%
Finally, the model is fitted with the main model-fitting function \fct{bayesx}
<<fit-illustration, echo=TRUE, eval=FALSE, fig=FALSE>>=
b <- bayesx(f, family = "gaussian", method = "MCMC",
  data = ZambiaNutrition)
@
<<cache-illustration, echo=FALSE, eval=TRUE>>=
if(file.exists("illustration-model.rda")) {
load("illustration-model.rda")
} else {
<<fit-illustration>>
save(b, file = "illustration-model.rda")
}
@
%
The model summary is displayed by calling
<<summary-illustration, echo=TRUE, fig=FALSE, eval=TRUE>>=
summary(b)
@

\begin{figure}[t!]
\setkeys{Gin}{width=0.46\textwidth}
\centering
<<plot-illustration-mbmi, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 1.1))
plot(b, term = "sx(mbmi)")
@
<<plot-illustration-agechild, echo=FALSE, fig=TRUE, width=5, height=4, pdf=FALSE, png=TRUE>>=
par(mar = c(4.1, 4.1, 0.1, 1.1))
plot(b, term = "sx(agechild)", residuals = TRUE, cex = 0.1, rug = FALSE)
@
\\[2ex]
\setkeys{Gin}{width=0.46\textwidth}
\hspace*{0.3cm}
<<plot-illustration-district, echo=FALSE, fig=TRUE, width=5.3, height=4, pdf=FALSE, png=TRUE>>=
par(mar = c(0, 0, 0, 0))
plot(b, term = "sx(district)", map = ZambiaBnd, swap = TRUE)
@
\caption{\label{fig:illustration} Visualization examples: Estimated effect for covariate \code{mbmi}
(black line) together with 95\% and 80\% credible intervals (upper left panel). The upper right
panel shows the estimated effect of \code{agechild} including partial residuals. The lower panel
illustrates visualization of the estimated spatial effect for covariate \code{district} using
a map effect plot.}
\end{figure}
A plot of the estimated effect for covariate \code{mbmi} may then be produced by typing
<<illustration-plot-mbmi, echo=TRUE, fig=FALSE, eval=FALSE>>=
plot(b, term = "sx(mbmi)")
@
and for covariate \code{agechild} including partial residuals by
<<illustration-plot-agechild, echo=TRUE, fig=FALSE, eval=FALSE>>=
plot(b, term = "sx(agechild)", residuals = TRUE)
@
The estimated effect of the correlated spatial effect of the districts in Zambia may e.g.,
be visualized using a map effect plot generated by
<<summary-illustration, echo=TRUE, fig=FALSE, eval=FALSE>>=
plot(b, term = "sx(district)", map = ZambiaBnd)
@
The plots are shown in Figure~\ref{fig:illustration}, depicting the centered additive effects
(i.e., each of the additive effects is zero on average). The map effect plot indicates
pronounced stunting (i.e., low values of the response) in the northern parts of Zambia.
Furthermore, stunting effects are lower (i.e., the response is higher) for children younger
than 20~months of age, while the \code{agechild} effect is almost constant for ages above 20~months.
Finally, the response increases almost linearly with increasing mother's BMI.
In comparison, the effects of \code{mbmi} and the spatial effect seem to have a quite similar influence
in absolute magnitude (indicated by the ranges of the respective axes), while the strongest
driver of stunting appears to be covariate \code{agechild}. Extended analyses of the data
are discussed in Sections~\ref{subsec:zambia} and~\ref{subsec:zambia-step}.


\section{STAR models} \label{sec:model}

The STAR model class supported by \pkg{R2BayesX} is based on the framework of Bayesian generalized
linear models (GLMs, see e.g., \citealp{R2BayesX:Fahrmeir+Kneib+Lang:2009} and
\citealp{R2BayesX:Fahrmeir+Tutz:2001}). GLMs assume that, given covariates $\mathbf{x}$ and unknown
parameters $\boldsymbol{\gamma}$, the distribution of the response variable $y$ belongs to an
exponential family with mean
$\mu = E(y | \mathbf{x}, \boldsymbol{\gamma})$ linked to a linear predictor $\eta$ by
\begin{equation*} \label{eqn:glm}
\mu = h^{-1}(\eta), \qquad \eta = \mathbf{x}^{\top}\boldsymbol{\gamma},
\end{equation*}
where $h$ is a known link function and $\boldsymbol{\gamma}$ are unknown regression coefficients. In
STAR models \citep{R2BayesX:Fahrmeir+Kneib+Lang:2004, R2BayesX:Brezger+Lang:2006}, the linear
predictor is replaced by a more general and flexible, structured additive predictor
\begin{equation} \label{eqn:structadd}
\eta = f_1(\mathbf{z}) + \ldots + f_p(\mathbf{z}) + \mathbf{x}^{\top}\boldsymbol{\gamma},
\end{equation}
with $\mu = E(y | \mathbf{x}, \mathbf{z}, \boldsymbol{\gamma}, \boldsymbol{\theta})$ and $\mathbf{z}$
represents a generic vector of all nonlinear modeled covariates. 
The vector $\boldsymbol{\theta}$ comprises all parameters of the functions $f_1, \dots,f_p$. 
The functions $f_j$ are possibly smooth functions encompassing various types of effects, e.g.:
\begin{itemize}
  \item Nonlinear effects of continuous covariates: $f_j(\mathbf{z}) = f(z_1)$.
  \item Two-dimensional surfaces: $f_j(\mathbf{z}) = f(z_1, z_2)$.
  \item Spatially correlated effects: $f_j(\mathbf{z}) = f_{spat}(z_s)$.
  \item Varying coefficients: $f_j(\mathbf{z}) = z_1f(z_2)$.
  \item Spatially varying effects: $f_j(\mathbf{z}) = z_1f_{spat}(z_s)$ or
    $f_j(\mathbf{z}) = z_1f(z_2, z_3)$.
  \item Random intercepts with cluster index $c$: $f_j(\mathbf{z}) = \beta_c$.
  \item Random slopes with cluster index $c$: $f_j(\mathbf{z}) = z_1\beta_c$.
\end{itemize}
STAR models cover a number of well known model classes as special cases, including generalized
additive models (GAM, \citealp{R2BayesX:Hastie+Tibshirani:1990}), generalized additive mixed models
(GAMM, \citealp{R2BayesX:Lin+Zhang:1999}), geoadditive models \citep{R2BayesX:Kamman+Wand:2003},
varying coefficient models \citep{R2BayesX:Hastie+Tibshirani:1993}, and geographically weighted
regression \citep{R2BayesX:Fotheringham+Brunsdon+Charlton:2002}.

The unified representation of a STAR predictor arises from the fact that all functions $f_j$ in
(\ref{eqn:structadd}) may be specified by a basis function approach, where the vector of function
evaluations $\mathbf{f}_j = (f_j(\mathbf{z}_{1}),\ldots,f_j(\mathbf{z}_{n}))^{\top}$ of the
$i = 1,\ldots,n$ observations can be written in matrix notation
\begin{equation*} \label{eqn:matnot}
\mathbf{f}_j = \mathbf{Z}_j\boldsymbol{\beta}_j,
\end{equation*}
where the design matrix $\mathbf{Z}_j$ depends on the specific term structure chosen for $f_j$
and $\boldsymbol{\beta}_j$ are unknown regression coefficients to be estimated. Hence, the predictor
 (\ref{eqn:structadd}) may be rewritten as
\begin{equation*} \label{eqn:structaddmat}
\boldsymbol{\eta} = \mathbf{Z}_1\boldsymbol{\beta}_1 + \ldots + \mathbf{Z}_p\boldsymbol{\beta}_p
+ \mathbf{X}\boldsymbol{\gamma},
\end{equation*}
where $\mathbf{X}$ corresponds to the usual design matrix for the linear effects.

To ensure particular functional forms, prior distributions are assigned to the regression
coefficients. The general form of the prior for $\boldsymbol{\beta}_j$ is
\begin{equation*} \label{eqn:prior}
p(\boldsymbol{\beta}_j | \tau_j^2) \propto \exp \left(- \frac{1}{2\tau_j^2}
\boldsymbol{\beta_j}^{\top}\mathbf{K}_j\boldsymbol{\beta}_j\right),
\end{equation*}
where $\mathbf{K}_j$ is a quadratic penalty matrix that shrinks parameters towards zero or penalizes
too abrupt jumps between neighboring parameters. In most cases $\mathbf{K}_j$ will be rank deficient and the
prior for $\boldsymbol{\beta}_j$ is partially improper.

The variance parameter $\tau_j^2$ is equivalent to the inverse smoothing parameter in a frequentist
approach and controls the trade off between flexibility and smoothness. For full Bayesian inference,
weakly informative inverse Gamma hyperpriors $\tau_j^2 \sim IG(a_j, b_j)$ are assigned to
$\tau_j^2$, with $a_j = b_j = 0.001$ as a standard option. Small values for $a_j$ and $b_j$
correspond to an approximate uniform distribution for $\log \tau_j^2$. For empirical Bayes inference,
$\tau_j^2$ is considered an unknown constant which is determined via restricted maximum likelihood
(REML).

In \pkg{BayesX}, estimation of regression parameters is based on three inferential concepts:
\begin{enumerate}
\item \textit{Full Bayesian inference via MCMC} \\
A fully Bayesian interpretation of STAR models is obtained by specifying prior distributions for all
unknown parameters. Estimation is carried out using MCMC simulation techniques.
\pkg{BayesX} provides numerically efficient implementations of MCMC schemes for structured additive
regression models. Suitable proposal densities have been developed to obtain rapidly mixing,
well-behaved sampling schemes without the need for manual tuning
\citep{R2BayesX:Brezger+Lang:2006}.

\item \textit{Inference via a mixed model representation} \\
Another concept used for estimation is based on mixed model methodology. The general idea is to take
advantage of the close connection between penalty concepts and corresponding random effects
distributions. The smoothing variances of the priors then transform to variance components in the
random effects (mixed) model. While regression coefficients are estimated based on penalized
likelihood, restricted maximum likelihood or marginal likelihood estimation forms the basis for the
determination of smoothing parameters. From a Bayesian perspective, this yields empirical
Bayes/posterior mode estimates for the STAR models. However, estimates can also merely be
interpreted as penalized likelihood estimates from a frequentist perspective
\citep{R2BayesX:Fahrmeir+Kneib+Lang:2004}.

\item \textit{Penalized likelihood including variable selection} \\
As a third alternative \pkg{BayesX} provides a penalized least squares (or penalized likelihood)
approach for estimating STAR models. In addition, a powerful variable and model selection tool is
included. Model choice and estimation of the parameters is done simultaneously. The algorithms are
able to
\begin{itemize}
  \item decide whether a particular covariate enters the model,
  \item decide whether a continuous covariate enters the model linearly or nonlinearly,
  \item decide whether a spatial effect enters the model,
  \item decide whether a unit- or cluster-specific heterogeneity effect enters the model
  \item select complex interaction effects (two dimensional surfaces, varying coefficient terms)
  \item select the degree of smoothness of nonlinear covariate, spatial or cluster specific
    heterogeneity effects.
\end{itemize}
Inference is based on penalized likelihood in combination with fast algorithms for selecting
relevant covariates and model terms. Different models are compared via various goodness of fit
criteria, e.g., Akaika or Bayes information criterion (AIC or BIC), generalized cross-validation
(GCV), or 5- or 10-fold cross-validation \citep{R2BayesX:Belitz+Lang:2008}.
\end{enumerate}

A thorough introduction into the regression models supported by the program is also provided in the
\pkg{BayesX} methodology manual \citep{R2BayesX:Belitz+Brezger+Kneib+Lang:2011}.


\section[Implementation of the R interface to BayesX]{Implementation of the \proglang{R} interface to \pkg{BayesX}} \label{sec:implementation}

The design of the interface  attempts to address the following major issues: First, the interface
functions should be follow \proglang{R}'s conventions for regression model fitting functions
so that they are easy to employ for \proglang{R} users. Second, the functions and methods for
representing fitted model objects should reflect \pkg{BayesX} models to enhance their
usability.

\subsection{Interface approach}

The first challenge in establishing a communication between \proglang{R} and \pkg{BayesX}
is the question which interface to use. As \pkg{BayesX} is written in \proglang{C++}, one
might expect that \fct{.C} or \fct{.Call} could be an option. However, as \pkg{BayesX} was
designed as a standalone software it does not offer an application programming interface (API)
and restructuring the mature and complex \pkg{BayesX} \proglang{C++} code to obtain an API
at this point is not straightforward. Hence, \pkg{R2BayesX} adopts the simpler approach of writing the data
out from \proglang{R}, calling the \pkg{BayesX} binary with a suitable program file, and then
collecting all output files and representing them in suitable \proglang{R} objects. This is
straightforward and the additional computation effort (as compared to a direct call)
is rather modest compared to time needed for carrying out the estimation of STAR models
within \pkg{BayesX}. 

Thus, for the interface adopted by \pkg{R2BayesX} a binary installation of \pkg{BayesX} is
required. To make this easily available to \proglang{R} users in a standardized way,
the \pkg{BayesX} \proglang{C++} sources are encapsulated in \proglang{R} package
\pkg{BayesXsrc} along with \code{Makefile}s for GNU/BSD and MinGW platforms
that conform with \proglang{R} build shells. Consequently, upon installation of the
\pkg{BayesXsrc} package, the binary \code{BayesX} (or \code{BayesX.exe} on Windows) is
created in the installed package. Package \pkg{BayesXsrc} is also available from CRAN
at \url{http://CRAN.R-project.org/package=BayesXsrc} and some of its implementation details
are discussed in Appendix~\ref{appendix:BayesXsrc}.


\subsection{Model specification}

The second challenge for the interface package \pkg{R2BayesX} is to employ an objects and
methods interface that reflects the workflow typically adapted by \proglang{R} packages
for fitting GAMs and related models. CRAN packages that implement such models include the
following prominent ones: One of the first implementations of GAMs in \proglang{R} is the
\pkg{gam} package \citep{R2BayesX:Hastie+Tibshirani:1990, R2BayesX:Hastie:2011}. The package is
supporting local regression and smoothing splines in combination with a backfitting algorithm and is
actually a version of the \proglang{S-PLUS} routines for GAMs. The probably best-known and also
recommended package is \pkg{mgcv} \citep{R2BayesX:Wood:2006,
R2BayesX:Wood:2011b, R2BayesX:Wood:2011}, which provides fast and stable algorithms for estimating
GAMs based on GCV, REML and others. Vector generalized additive models (VGAMs,
\citealp{R2BayesX:Yee:1996}) for categorical responses are covered by package \pkg{VGAM}
\citep{R2BayesX:Yee:2009}. Another comprehensive toolbox for GAMs, accounting for responses that do
not necessarily follow the exponential family and may exhibit heterogeneity, is the \pkg{gamlss}
suite of packages \citep{R2BayesX:Rigby+Stasinopoulos:2005, R2BayesX:Stasinopoulos:Rigby:2007}. A package based on
mixed model technologies is \pkg{SemiPar} \citep{R2BayesX:Ruppert+Wand+Carrol:2003,
R2BayesX:Wand:2010} and, building on top of this, the \pkg{AdaptFit} package for adaptive splines
\citep{R2BayesX:Krivobokova}. The package \pkg{spikeSlabGAM} applies Bayesian variable selection,
model choice and regularization for GAMMs \citep{R2BayesX:Scheipl:2011}.

Most of these packages follow the common \proglang{R} paradigm of specifying regression models
conveniently using its formula language \citep{R2BayesX:Chambers+Hastie:1992}. However, the
above-mentioned packages employ somewhat different approaches for representing smooth/special
terms for GAMs in formulas and the subsequent building of model frames. A popular approach, though,
is to use a model term constructor function ``\code{s}'', as used in packages
\pkg{gam}, \pkg{mgcv}, and \pkg{VGAM}. As the implementation details are somewhat different across
these packages, loading packages simultaneously may lead to conflicts. Therefore, \pkg{R2BayesX}
follows the approach of the recommended package \pkg{mgcv} where
\fct{s} does not evaluate design or penalty matrices, but simply returns a smooth term definition object
of class \class{xx.smooth.spec}, where \code{"xx"} may be specified by the user. To set up a model
with a user-defined smooth term, a method for the \proglang{S}3 generic function \fct{smooth.construct}
needs to be supplied, that returns a design matrix etc. Since implementation of additional model
terms is also a concern for \pkg{R2BayesX} and function \fct{s} is a very lean solution, we
adopt its functionality and provide methods for a new generic function \fct{bayesx.construct},
that returns the required command for a particular smooth term in \pkg{BayesX}. To give an example,
we generate a call to function \fct{s} with some covariate \code{x} specifying a P-spline term and
return the \pkg{BayesX} command with
<<implementation-bayesx.construct, echo=TRUE, eval=TRUE>>=
bayesx.construct(s(x, bs = "ps"))
@
Given an \proglang{R} model formula, the specified terms are translated one after another and
finally merged into a complete program which may be sent to \pkg{BayesX}. In addition to the
support of \pkg{mgcv}'s \fct{s} function, a second smooth term constructor \fct{sx} is provided
(described in detail in Section~\ref{subsec:addterms}). This is essentially a convenience interface
that calls \fct{s} but uses somewhat different defaults and additional options specific to the
terms supported by \pkg{BayesX}. Moreover, a special constructor function \fct{r} for random effect
terms is provided.

\subsection{Under the hood}

The main user interface of \pkg{R2BayesX} is the function \fct{bayesx}
(presented in detail in Section~\ref{subsec:processing}). Internally, this function employs
the helper functions \fct{parse.bayesx.input}, \fct{write.bayesx.input}, \fct{run.bayesx}, and
\fct{read.bayesx.output} in the following work sequence: First, a
program file is generated by applying function \fct{parse.bayesx.input} to the
\proglang{R} input parameters, including the model \code{formula}, \code{data}, etc. The returned
object is then further processed with function \fct{write.bayesx.input}, utilizing the methods
described above, as well as setting up the necessary temporary directories and data files to be used with
\pkg{BayesX}. Afterwards, function \fct{run.bayesx} (provided in \pkg{BayesXsrc}) executes the
program through a call to function \fct{system}. The output files returned by the binary are imported
into \proglang{R} using function \fct{read.bayesx.output}. 
Using these helper functions it is also possible to run and read already existing \pkg{BayesX}
program and output files, see Section~\ref{sec:addoptions} and the \pkg{R2BayesX} manuals for a
detailed description. The object returned by function \fct{read.bayesx.output} is a list of class
\class{bayesx}, for which a set of base \proglang{R} functions and methods described in
Table~\ref{tab:funmethods}, amongst others, is available. The returned fitted model term objects also
have suitable classes along with corresponding plotting methods. Particular effort has been given on
the development of easy-to-use map effect plots using color legends (by default employing HCL-based palettes,
\citealp{R2BayesX:Zeileis+Hornik+Murrell:2009}, from the \pkg{colorspace} package, \citealp{R2BayesX:Ihaka+Murrell+Hornik:2012}).
See also Section~\ref{sec:userinterface} for more details and Section~\ref{sec:illustrations} for
some practical applications.


\section[User interface]{User interface} \label{sec:userinterface}

\subsection[Calling BayesX from R]{Calling \pkg{BayesX} from \proglang{R}}
\label{subsec:processing}

\hypertarget{bayesx}{The} main model-fitting function in the package \pkg{R2BayesX} is called
\fct{bayesx}. The arguments of \fct{bayesx} are
\begin{Code}
  bayesx(formula, data, weights = NULL, subset = NULL, offset = NULL,
    na.action = NULL, contrasts = NULL,
    family = "gaussian", method = "MCMC", control = bayesx.control(...), ...)
\end{Code}
where the first two lines basically represent the standard model frame specifications
\citep[see][]{R2BayesX:Chambers+Hastie:1992} and the third line collects the arguments
specific to \pkg{BayesX}.

The data processing is carried out ``as usual'' as in \fct{lm} or \fct{glm} with
the following additions: (1)~The \code{data} can not only be provided as a
\class{data.frame} but it is also possible to provide a character string
with a path to a dataset stored on disc, which can be leveraged to avoid reading very
large data files into \proglang{R} just to write them out again for \pkg{BayesX}.
An example is given in Section~\ref{sec:addoptions}. (2)~Additional contrast specifications for 
factor variables can be passed to argument \code{contrasts}. Using factors, we recommend deviation
or effect coding (see function \fct{contr.sum}) rather than the usual dummy coding of factors as it
typically improves  convergence of estimation algorithms used in \pkg{BayesX}. 

The \pkg{BayesX}-specific arguments comprise specification of the response distribution \code{family},
the estimation \code{method} and further control parameters collected in \fct{bayesx.control}.
The default response distribution is \code{family = "gaussian"}. Note that \class{family} objects
(in the \fct{glm} sense) are currently not supported by \pkg{BayesX}.
The inferential concepts that can be used as the estimation \code{method} comprise:
\code{"MCMC"} for Markov chain Monte Carlo simulation,
\code{"REML"} for mixed-model-based estimation using restricted maximum likelihood/marginal likelihood, and
\code{"STEP"} for penalized likelihood including model selection.
An overview of all available distributions for the different methods is given in Table~\ref{tab:family}.

\begin{table}[t!]
\centering
\begin{tabular}{lp{4cm}p{1.2cm}l}
\hline
\code{family} & Response distribution & Link & \code{method} \\ \hline
\code{"binomial"} & binomial & logit & \code{"MCMC"} \code{"REML"} \code{"STEP"} \\
\code{"binomialprobit"} & binomial & probit  & \code{"MCMC"} \code{"REML"} \code{"STEP"} \\
\code{"gamma"} & gamma & log & \code{"MCMC"} \code{"REML"} \code{"STEP"} \\
\code{"gaussian"} & Gaussian & identity & \code{"MCMC"} \code{"REML"} \code{"STEP"} \\
\code{"multinomial"} & unordered multinomial & logit & \code{"MCMC"} \code{"REML"} \code{"STEP"} \\
\code{"poisson"} & Poisson & log & \code{"MCMC"} \code{"REML"} \code{"STEP"} \\ \hline
\code{"cox"} & continuous-time survival data &  & \code{"MCMC"} \code{"REML"} \\
\code{"cumprobit"} & cumulative threshold & probit & \code{"MCMC"} \code{"REML"} \\
\code{"multistate"} & continuous-time multi-state data & & \code{"MCMC"} \code{"REML"} \\ \hline
\code{"binomialcomploglog"} & binomial & compl. log-log & \code{"REML"} \\
\code{"cumlogit"} & cumulative multinomial & logit & \code{"REML"} \\
\code{"multinomialcatsp"} & unordered multinomial (with category-specific covariates) & logit &
  \code{"REML"} \\
\code{"multinomialprobit"} & unordered multinomial & probit & \code{"MCMC"} \\
\code{"seqlogit"} & sequential multinomial & logit & \code{"REML"} \\
\code{"seqprobit"} & sequential multinomial & probit & \code{"REML"}  \\ \hline
\end{tabular}
\caption{\label{tab:family} Distributions implemented for \code{method}s \code{"MCMC"},
\code{"REML"} and \code{"STEP"}.}
\end{table}
The last argument specifies several parameters controlling the processing of the \pkg{BayesX} binary 
that are arranged by function \fct{bayesx.control}. Note that all additional controlling arguments
are automatically parsed within function \fct{bayesx} using the dot dot dot argument ``\code{...}'',
which is sent to \fct{bayesx.control}. The most important parameters for the different methods are
listed in Table~\ref{tab:control}.
\begin{table}[p!]
\centering
\begin{tabular}{llp{10.5cm}}
\hline

\code{method} & Parameter & Description \\ \hline

\code{"MCMC"} & \code{iterations} & Integer number of iterations
                                         for the sampler, default: \code{12000}. \\
 & \code{burnin} & Integer burn-in period of the sampler, default: \code{2000}. \\
 & \code{step} & Integer, defines the thinning parameter for MCMC simulation. E.g., \code{step = 50}
              means, that only every 50th sampled parameter will be stored and used to compute
              characteristics of the posterior distribution as means, standard deviations or
              quantiles, default: \code{10}. \\ \hline
\code{"REML"} & \code{eps} & Numeric, defines the termination criterion of
                                         the estimation process. If both the relative changes in the
                                         regression coefficients and the variance parameters are
                                         less than \code{eps}, the estimation process is assumed to
                                         have converged, default: \code{0.00001}. \\
 & \code{maxit} & Integer, defines the maximum number of iterations to be used in estimation. Since
               the estimation process will not necessarily converge, it may be useful to define an
               upper bound for the number of iterations. \\
 & \code{algorithm} & Character, specifies the selection
                   algorithm. Possible values are \code{"cdescent1"} (adaptive algorithms see
                   Section~6.3 in \citealp{R2BayesX:Belitz+Brezger+Kneib+Lang:2011}),
                   \code{"cdescent2"} (adaptive algorithms 1 and 2 with backfitting, see remarks 1
                   and 2 of Section~3 in \citealp{R2BayesX:Belitz+Lang:2008}), \code{"cdescent3"}
                   (search according to \code{"cdescent1"} followed by \code{"cdescent2"} using the selected model in
                   the first step as the start model) and \code{"stepwise"} (stepwise algorithm
                   implemented in the \code{gam} function of \proglang{S-PLUS}, see
                   \citealp{R2BayesX:Chambers+Hastie:1992}), default: \code{"cdescent1"}. \\ \hline
\code{"STEP"} & \code{criterion} & Character, specifies the goodness of fit
                   criterion, possible criterions are:
                   \code{"MSEP"} (divides the data randomly into a test- and validation dataset. The
                   test dataset is used to estimate the models and the validation dataset is used to
                   estimate the mean squared prediction error which serves as the goodness of
                   fit criterion to compare different models),
                   \code{"GCV"} (generalized cross-validation based on deviance residuals), 
                   \code{"GCVrss"} (GCV based on residual sum of squares),
                   see e.g., \cite{R2BayesX:Wood:2006},
                   \code{"AIC"} (Akaike information criterion),
                   \code{"AIC\_imp"} (improved AIC with bias correction for regression models),
		   see e.g., \cite{R2BayesX:Burnham+Anderson:1998},
                   \code{"BIC"} (Bayesian information criterion)
                   \code{"CV5"} (5-fold cross validation)
                   \code{"CV10"} (10-fold CV),
		   see e.g., \cite{R2BayesX:Hastie+Tibshirani+Friedmann:2009}, and
                   \code{"AUC"} (area under the ROC curve, binary response only), default:
                   \code{"AIC\_imp"}. \\
 & \code{startmodel} & Character, defines the start model for variable selection. Options are
                    \code{"linear"} (model with degrees of freedom equal to one for model
                    terms), \code{"empty"} (empty model containing only an intercept), \code{"full"}
                    (most complex possible model) and \code{"userdefined"} (user-specified model),
		    default: \code{"linear"}. \\
\hline
\end{tabular}
\caption{\label{tab:control} Most important controlling parameters for the different methods using
function \fct{bayesx}. See \code{?bayesx.control} for more details.}
\end{table}

The returned fitted model object is a list of class \class{bayesx}, which is supported by several
standard methods and extractor functions, such as \fct{plot} and \fct{summary}. For models estimated using
method \code{"REML"}, function \fct{summary} generates summary statistics similar to objects
returned from the main model fitting function \fct{gam} of the \pkg{mgcv} package. For \code{"MCMC"}
estimated models, the mean, standard deviation and quantiles of parameter samples are provided.
Using \code{"STEP"}, the parametric part of the summary statistics is represented like
\code{"MCMC"}, i.e., if computed, the confidence bands are based on an MCMC algorithm subsequent to
the model selection, while the remaining summary is similar to \code{"REML"}. The implemented
\proglang{S}3 methods for plotting fitted term objects are quite flexible, i.e., depending on the
term structure, the generic function \fct{plot} calls one of the following functions: for 2d plots
function \fct{plot2d} or \fct{plotblock} (for factors, unit- or cluster specific plots, draws a
block for every estimated parameter including mean and credible intervals), for perspective or image
and contour plots function \fct{plot3d}, map effects plots are produced by function \fct{plotmap},
with or without colorlegends drawn by function \fct{colorlegend}, amongst others. See
Appendix~\ref{appendix:plotting} for an overview of the most important arguments for
the plotting functions. For MCMC post-estimation diagnosis, besides the
implemented trace and autocorrelation plots, samples of the parameters may also be extracted using
function \fct{samples}. The sampling paths are provided as a data frame, and hence may easily be
converted to objects of class \class{mcmc} using the \pkg{coda} package
\citep{R2BayesX:Plummer+Best+Cowles+Vines:2006} for further analysis. In addition, an \proglang{R}
script for the estimated model, including function calls for saving, loading, plotting of term
effects and diagnostic plots, may be generated using function \fct{getscript}. The produced
\proglang{R} script may be useful for less experienced users of the package to get a quick overview
of post-estimation commands. Moreover, the script facilitates the final preparation of plots and
diagnostics to be included in publications. In some situations it may be useful to inspect the log file generated by the
\pkg{BayesX} binary. The file can either be viewed directly during fitting process when setting
\code{verbose = TRUE}, or it can be extracted from the fitted
model object using function \fct{bayesx\_logfile}. 
A list of all available functions and methods of package
\pkg{R2BayesX} can be found in Table~\ref{tab:funmethods}.

\begin{table}[t!]
\centering
\begin{tabular}{p{3cm}p{11.5cm}}
\hline
Function & Description \\ \hline
\fct{print} & Simple printed display of the initial call and some additional information of the
              fitted model. \\
\fct{summary} & Return an object of class \class{summary.bayesx} containing the relevant summary
                statistics (which has a \fct{print} method). \\ \hline
\fct{coef} & Extract coefficients of the linearly modeled terms. \\
\fct{confint} & Compute confidence intervals of linear modeled terms if \code{method = "REML"}, for
                \code{"MCMC"} the quantiles of the coefficient samples according to a specified
                probability level are computed. \\
\fct{cprob} & Extract contour probabilities of a particular P-spline term, only meaningful if
              \code{method = "MCMC"} and argument \code{contourprob} is specified as an additional
              argument in the term constructor function \fct{sx}, or within argument \code{xt} in
              function \fct{s}. E.g., in the introductory example, contour probabilities for \code{mbmi}
	      are estimated with \code{s(mbmi, bs = "ps", xt = list(contourprob = 4))} (see also
              Section~\ref{subsec:addterms}). \\
\fct{fitted} & Fitted values of either the mean and linear predictor, or a selected model term. \\
\fct{residuals} & Extract model or partial residuals for a selected term. \\
\fct{samples} & Extract samples of parameters from MCMC simulation. \\ 
\fct{bayesx\_logfile} & Extract the internal \pkg{BayesX} log file. \\
\fct{bayesx\_prgfile} & Extract the \pkg{BayesX} program file. \\
\fct{bayesx\_runtime} & Extract the overall runtime of the \pkg{BayesX} binary. \\ \hline
\fct{terms} & Extract terms of model components. \\
\fct{model.frame} & Extract/generate the model frame. \\
\fct{logLik} & Extract fitted log-likelihood, only if \code{method = "REML"}. \\ \hline
\fct{plot} & Either model diagnostic plots or effect plots of particular terms. \\
\fct{getscript} & Generate an \proglang{R} script for term effect, diagnostic plots and model
                  summary statistics. \\ \hline
\fct{AIC}, \fct{BIC}, \phantom{123} \fct{DIC}, \fct{GCV} & Compute information criteria,
                                             availability is dependent on the \code{method} used.
                                             \\ \hline
\end{tabular}
\caption{\label{tab:funmethods} Functions and methods for objects of class \class{bayesx}. More details
are provided in the manual pages.}
\end{table}


\subsection[Available additive terms]{Available additive terms}
\label{subsec:addterms}
In package \pkg{R2BayesX}, the main constructor function for specifying additive terms in STAR
\code{formula}s is called \fct{sx}. The function is basically an interface to the term constructor
function \fct{s} of package \pkg{mgcv}, also see Section~\ref{sec:implementation}.
The arguments of function \fct{sx} are
\begin{Code}
  sx(x, z = NULL, bs = "ps", by = NA, ...)
\end{Code}
where \code{x} represents the covariate that is used for univariate terms and \code{z} is
used additionally for bivariate model terms. Argument \code{bs} chooses the basis/type of the term, 
see Table~\ref{tab:terms} for possible options of \code{bs} (and note that some terms have equivalent
short and long specifications, e.g., \code{bs = "ps"} or \code{bs = "psplinerw2"}). Argument
\code{by} can be a  numeric or a factor variable to estimate varying coefficient terms, where
the effect of the variable provided to \code{by} varies over the range of the covariate(s) of this
term. Finally, the ``\code{...}'' argument is used to set term-specific control parameters
or additional geographical information.

\begin{table}[p!]
\centering
\begin{tabular}{p{3.2cm}p{11.5cm}}
\hline
\code{bs} & Description \\ \hline
\code{"rw1"}, \code{"rw2"} & Zero degree P-splines: Defines a zero degree P-spline with first or
                            second order difference penalty. A zero degree P-spline typically
                            estimates for every distinct covariate value in the dataset a separate
                            parameter. Usually there is no reason to prefer zero degree P-splines
                            over higher order P-splines. An exception are ordinal covariates or
                            continuous covariates with only a small number of different values.
                            For ordinal covariates higher order P-splines are not meaningful while
                            zero degree P-splines might be an alternative to modeling nonlinear
                            relationships via a dummy approach with completely unrestricted
                            regression parameters. \\
\code{"season"} & Seasonal effect of a time scale. \\
\code{"ps"}, \code{"psplinerw1"}, \code{"psplinerw2"} & P-spline with first or second order 
                                                        difference penalty. \\
\code{"te"}, \code{"pspline2dimrw1"} & Defines a two-dimensional P-spline based on the tensor 
              product of one-dimensional P-splines with a two-dimensional first order random walk 
              penalty for the parameters of the spline. \\
\code{"kr"}, \code{"kriging"} & Kriging with stationary Gaussian random fields. \\ \hline

\code{"gk"}, \code{"geokriging"} & Geokriging with stationary Gaussian random fields: Estimation
              is based on the centroids of a map object provided in 
              boundary format (see function \fct{read.bnd} and \fct{shp2bnd}) as an additional
              argument named \code{map} within function \fct{sx}, or supplied within argument
              \code{xt} when using function \fct{s}, e.g., \code{xt = list(map = MapBnd)}. \\
\code{"gs"}, \code{"geospline"} & Geosplines based on two-dimensional P-splines with a
              two-dimensional first order random walk penalty  for the parameters of the spline.	      
	      Estimation is based on the coordinates of the centroids of the regions 
              of a map object provided in boundary format (see function \fct{read.bnd} and
              \fct{shp2bnd}) as an additional argument named \code{map} (see above). \\
\code{"mrf"}, \code{"spatial"} & Markov random fields: Defines a Markov random field prior for a 
               spatial covariate, where geographical information is provided by a map object in 
               boundary or graph file format (see function \fct{read.bnd}, \fct{read.gra} and
               \fct{shp2bnd}), as an additional argument named \code{map} (see above). \\ \hline

\code{"bl"}, \code{"baseline"} & Nonlinear baseline effect in hazard regression or multi-state 
              models: Defines a P-spline with second order random walk penalty for the parameters of 
              the spline for the log-baseline effect $\log(\lambda(\mathit{time}))$. \\
\code{"factor"} & Special \pkg{BayesX} specifier for factors, especially meaningful if
                  \code{method = "STEP"}, since the factor term is then treated as a full term,
                  which is either included or removed from the model. \\
\code{"ridge"}, \code{"lasso"}, \code{"nigmix"} & Shrinkage of fixed effects: Defines a
                                                shrinkage-prior for the corresponding parameters
                                                $\gamma_j$, $j = 1, \ldots, q$, $q \geq 1$ of the
                                                linear effects $x_1, \ldots, x_q$. There are three
                                                priors possible: ridge-, lasso- and normal mixture
                                                of inverse gamma prior. \\ \hline
\code{"re"} & Gaussian i.i.d. Random effects of a unit or cluster identification covariate. \\ \hline
\end{tabular}
\caption{\label{tab:terms} Possible \pkg{BayesX} model terms within function \fct{sx}.}
\end{table}

For example to modify the degree and the inner knots for the P-spline term \code{sx(mbmi)}
from Section~\ref{sec:motivation}, \code{sx(mbmi, degree = 2, knots = 10)} could be used.
Information about all possible extra arguments for a particular term basis/type can be looked up using
function \fct{bayesx.term.options}, e.g., possible options for P-splines using \code{"MCMC"} are shown by 
<<bayesx.term.options1, echo=TRUE, eval=FALSE>>=
bayesx.term.options(bs = "ps", method = "MCMC")
@
<<bayesx.term.options2, echo=FALSE>>=
out <- capture.output(bayesx.term.options(bs = "ps", method = "MCMC"))
writeLines(c(out[1:9], "..."))
@
For simplicity, only the first two options are shown here.

For fitting geoadditive models utilizing spatial information -- i.e., by computing
suitable neighborhood penalty matrices for terms using Markov random field (MRF) priors,
or by calculating the centroids of particular regions for geosplines and geokriging terms --
an argument named \code{map} needs to be provided to \fct{sx}. For example, the 
map of Zambia in the geokriging term in Section~\ref{sec:motivation} is 
included with \code{sx(district, bs = "gk", map = ZambiaBnd)}. The \code{map}
argument can be an object of class \class{SpatialPolygonsDataFrame}
\citep{R2BayesX:Pebesma+Bivand:2005,R2BayesX:Bivand+Pebesma+GomezRubio:2008} or
an object of class \class{bnd}. The latter is essentially a named list of the map's polygons
which is the format required by \pkg{BayesX} for its computations. In case a
\class{SpatialPolygonsDataFrame} is supplied it is transformed internally to
such a polygon list which is employed for all further computations. Furthermore,
\class{bnd} objects can be created directly using functions from the \proglang{R}~package
\pkg{BayesX} of \cite{R2BayesX:Kneib+Heinzl+Brezger:2011}: \fct{read.bnd} and 
\fct{shp2bnd} create \class{bnd} objects from text files or shapefiles
(using package \pkg{shapefiles}, \citealp{R2BayesX:Stabler:2006}), respectively.
For MRF terms, it is possible to supply the whole map as outlined above but
it suffices to supply the corresponding neighborhood information. Internally,
\pkg{BayesX} uses a list specification of neighbors which is captured in objects
of class \class{gra} that can be created by \fct{read.gra} and \fct{bnd2gra}.
Improvements in the handling of spatial information -- especially by leveraging
more functionality from the \pkg{sp} family of packages -- are planned for future
versions of \pkg{R2BayesX}.

Some care is warranted for the identifiability of varying coefficients terms. The standard in
\pkg{BayesX} is to center nonlinear main effects terms around zero whereas varying coefficient terms 
are not centered. This makes sense since main-effects nonlinear terms are not identifiable
(with an intercept in the model) and  varying coefficients terms are usually identifiable.
However, there are situations where a varying
coefficients term is not identifiable. Then the term must be centered. Since centering is not
automatically accomplished it has to be enforced by the user by adding option \code{center = TRUE}
in function \fct{sx}. To give an example, the varying coefficient terms in
$\eta = \ldots + g_1(z_1)z + g_2(z_2)z + \gamma_0 + \gamma_1 z + \ldots$ are not identified, whereas
in $\eta = \ldots + g_1(z_1)z + \gamma_0 + \ldots$, the varying coefficient term is identifiable. In
the first case, centering is necessary, in the second case, it is not.

\subsection{Other additive term interfaces}

As mentioned above, users may optionally call the constructor function \fct{s} directly, since
\fct{sx} is only a wrapper function which calls \fct{s} in the end. The usage
of \fct{s} in \pkg{R2BayesX} is in principle similar to package \pkg{mgcv}. However, the applicable
arguments are limited to arguments corresponding to those also available in \pkg{BayesX}, i.e.,
\begin{Code}
  s(..., k = -1, bs = "ps", m = NA, by = NA, xt = NULL)
\end{Code}
Note that the defaults of \fct{s} (as provided by \pkg{mgcv}) are different from the values
above and would not correspond to a spline basis available in \pkg{BayesX}. Hence, the new
\fct{sx} function is introduced in \pkg{R2BayesX} as a more convenient interface with defaults
as in \pkg{BayesX}.

Within \fct{s}, the list of covariates used for the model term is set with argument ``\code{...}''. 
For instance, in the example of Section~\ref{sec:motivation}, the term for the body mass index of the
mother may also be included in the model formula by \code{s(mbmi)}, a term with two covariates is
specified e.g., with \code{s(mbmi, agechild)}. Here, the parameter \code{k} controls the dimension
of the basis used for smooth terms. Setting argument \code{m} is only meaningful for P-splines,
i.e., \code{bs = "ps"}, and controls the degree of the B-spline basis functions and the order of the
difference penalty. E.g., a B-spline of degree 3 with a 2nd order difference penalty is set with
\code{s(mbmi, bs = "ps", m = c(1, 2))} (note that argument \code{m} is slightly different than
argument \code{degree} in function \fct{sx} using P-splines, see also the manual of \fct{s}).
Argument \code{by} is used in the same way as for \fct{sx}. The additional parameters that are
specified by argument ``\code{...}'' in function \fct{sx}, may be set in \fct{s} within argument
\code{xt}, e.g., similar to the example above, the boundary object \code{ZambiaBnd} is supplied with
\code{s(district, bs = "gk", xt = list(map = ZambiaBnd))}. Besides \fct{s}, \pkg{R2BayesX} also
supports calls to the tensor product constructor function \fct{te}, however, only a small set of the 
features of this function is supported by \pkg{BayesX}.

%In addition to \fct{sx}, \fct{s}, and \fct{te}, unit- or cluster specific unstructured (random)
%effects may be incorporated into the model \code{formula} using the random effects term constructor
%function \fct{r}. The arguments of \fct{r} are
%\begin{Code}
%  r(id, by = NA, xt = NULL)
%\end{Code}
%where \code{id} is the unit or cluster identification covariate the random effects should be
%estimated for. E.g., the model formula from the introduction could be extended by a random effects
%term for the districts in Zambia with \code{r(district)}.  Argument \code{by} takes covariates
%for which random slopes may be estimated. Argument \code{xt} is used in the same way as
%described for function \fct{s}, i.e., similar to the above, e.g., hyperpriors $a$ and $b$ for the
%variance parameter are set  with \code{r(district, xt = list(a = 0.0001, b = 0.0001))}.


\subsection[Additional options]{Additional options} \label{sec:addoptions}

For practical purposes fitting models with function \fct{bayesx} is typically sufficient. However,
the interfacing functions that are called internally within \fct{bayesx} can also be used
independently. This could be useful for two reasons: First, users may want to use already
existing \pkg{BayesX} program files, and second, there might be a need for automated
importing of previously generated \pkg{BayesX} output files into \proglang{R} for further analysis.

\hypertarget{run.bayesx}{Function} \fct{run.bayesx}, included in package \pkg{BayesXsrc}, is used to
run an arbitrary \pkg{BayesX} program 
file. The arguments of \fct{run.bayesx} are
\begin{Code}
  run.bayesx(prg = NULL, verbose = TRUE, ...)
\end{Code}
where \code{prg} is a character string with the path to a program file to be executed. If argument
\code{prg} is not provided \pkg{BayesX} will start in batch mode. During processing of \pkg{BayesX}
several informations will be printed to the \proglang{R} console if \code{verbose = TRUE}. Further
arguments may be passed to function \fct{system}, which calls the \pkg{BayesX} binary, using the
``\code{...}'' argument. The function returns a list including the log-file returned by
\pkg{BayesX} as well as information on the total runtime.

\hypertarget{read.bayesx.output}{Model} output files are imported using function
\begin{Code}
  read.bayesx.output(dir, model.name = NULL)
\end{Code}
Here, \code{dir} is again a directory and \code{model.name} the name of the model the files are
imported for, also provided as character strings. Note that the function will search for all
different \pkg{BayesX}-estimated models in the declared directory if argument \code{model.name} is set to
\code{NULL}. The returned object is also of class \class{bayesx}, i.e., all the functions and
methods described in Table~\ref{tab:funmethods} may be applied.

Another noteworthy feature of package \pkg{R2BayesX} is the internal handling of data. \pkg{BayesX} 
uses numerically efficient algorithms including sparse matrix computations which in principle allow 
to estimate models using very large datasets. Moreover, the number of different observations for 
particular covariates is usually much smaller than the total number of observations. That is, the 
output files returned by the binary only include estimates for unique covariate values. Since these 
files typically reserve much less disc space, importing the fitted model objects into \proglang{R} 
using \fct{read.bayesx.output} is straightforward in most cases, whereas handling the complete 
dataset within \proglang{R} may be more burdensome when provided to model fitting functions that do
not account for special matrix structures. As mentioned in Section~\ref{subsec:processing}, users can exploit this by providing a character string
to argument \code{data} in function 
\fct{bayesx}, which includes the path to a dataset instead of an \proglang{R} data object. As a 
consequence, this dataset will not be loaded within \proglang{R} and is only used internally by the 
\pkg{BayesX} binary. To give an example, we generate a large dataset that might produce problems 
with \proglang{R}'s memory allocation using a model fitting function, especially if the model 
contains a large number of parameters. Therefore, we store the data on disc in the temporary folder 
of the running session with
<<large-data, echo=TRUE, eval=FALSE>>=
set.seed(321)
file <- paste(tempdir(), "/data.raw", sep = "")
n <- 5e+06
dat <- data.frame(x = rep(runif(1000, -3, 3), length.out = n))
dat$y <- with(dat, sin(x) + rnorm(n, sd = 2))
write.table(dat, file = file, quote = FALSE, row.names = FALSE)
@
This produces a dataset of approximately 170Mb with only 1000 unique observations for covariate
\code{x}. The path to the dataset is stored in object \code{file} and is provided to argument
\code{data} in the function call
<<large-data-01, echo=TRUE, eval=FALSE>>=
b <- bayesx(y ~ sx(x), family = "gaussian", method = "MCMC", 
  iterations = 3000, burnin = 1000, step = 2, predict = FALSE, 
  data = file, seed = 123)
@
For illustration purposes, the number of iterations is only set to 3000. Note that argument
\code{predict} is set to \code{FALSE}, i.e., only output files of estimated effects will be returned,
otherwise an expanded dataset using all observations would be written in the output directory, also
containing the data used for estimation. The runtime of this example is about 4 1/2 hours
\begin{Schunk}
\begin{Sinput}
R> bayesx_runtime(b)
\end{Sinput}
\begin{Soutput}
    user   system  elapsed 
16442.12     7.56 16461.33 
\end{Soutput}
\end{Schunk}
on a Linux system with an Intel 2.33GHz Dual Core processor, while the returned object \code{b} uses
\begin{Schunk}
\begin{Sinput}
R> print(object.size(b), units = "Mb")
\end{Sinput}
\begin{Soutput}
0.4 Mb
\end{Soutput}
\end{Schunk}
of memory size.


\section{STAR models in practice} \label{sec:illustrations}

The focus of this section is on demonstrating the various features of the \pkg{R2BayesX} package.
Therefore, the examples provided reconsider analyses from
\citet{R2BayesX:Brezger+Kneib+Lang:2005} and \citet{R2BayesX:Fahrmeir+Kneib+Lang:2009}. The
presented datasets have been added to package \pkg{R2BayesX}, ensuring straightforward reproducibility
of the following code. In the first example, a Gaussian regression model is estimated using Markov
chain Monte Carlo simulation. The second example covers estimation based on mixed-model technology,
where a cumulative threshold model is employed for an ordered response variable (see
\citealp{R2BayesX:Fahrmeir+Tutz:2001}, and \citealp{R2BayesX:Kneib+Fahrmeir:2004} for
cumulative threshold models). The last example
illustrates the approach of the stepwise algorithm for model and variable selection.

\subsection{Childhood malnutrition in Zambia: Analysis with MCMC} \label{subsec:zambia}

This analysis has already been conducted by \citet{R2BayesX:Kandala+Lang+Klasen+Fahrmeir:2001} and
has also been used as a demonstrating example in \citet{R2BayesX:Brezger+Kneib+Lang:2005}. Stunting
is one of the leading drivers of a number of problems development countries are faced with, for
instance, a direct consequence of stunting is a high mortality rate. Here, the primary interest is
to model the dependence of stunting of newborn children, with an age ranging from 0 to 5 years, on
covariates such as the body mass index of the mother, the age of the child and others presented in
Table~\ref{tab:zambia}.
\begin{table}[t!]
\centering
\begin{tabular}{lp{10cm}}
\hline
Variable           & Description \\ \hline
\code{stunting}    & Standardized $Z$-score for stunting. \\
\code{mbmi}        & Body mass index of the mother. \\
\code{agechild}    & Age of the child in months. \\
\code{district}    & District where the mother lives. \\
\code{memployment} & Mother's employment status with categories `yes' and `no'. \\
\code{meducation}  & Mother's educational status with categories for no education or incomplete
                     primary `no', complete primary but incomplete secondary `primary' and complete
                     secondary or higher `secondary'. \\
\code{urban}       & Locality of the domicile with categories `yes' and `no'. \\
\code{gender}      & Gender of the child with categories `male' and `female'. \\ \hline
\end{tabular}
\caption{\label{tab:zambia} Variables in the dataset on childhood malnutrition in Zambia.}
\end{table}
The response \code{stunting} is standardized in terms of a reference population, i.e., in this dataset
stunting for child $i$ is represented by
\begin{equation*}
\texttt{stunting}_i = \frac{\mathit{AI}_i - m}{\sigma},
\end{equation*}
where $\mathit{AI}$ refers to a child's anthropometric indicator (height at a certain age in our example),
while $m$ and $\sigma$ correspond to the median and the standard deviation in the reference
population, respectively.

Following \citet{R2BayesX:Kandala+Lang+Klasen+Fahrmeir:2001}, we estimate a structured additive
regression model with predictor
\begin{eqnarray} \label{eqn:zambia-eta}
\eta &=& \gamma_0 + \gamma_1\texttt{memploymentyes} + \gamma_2\texttt{urbanno} +
         \gamma_3\texttt{genderfemale} + \nonumber \\
     & & \gamma_4\texttt{meducationno} + \gamma_5\texttt{meducationprimary} + 
         \nonumber \\
     & & f_1(\texttt{mbmi}) + f_2(\texttt{agechild}) + f_{str}(\texttt{district}) +
         f_{unstr}(\texttt{district})
\end{eqnarray}
where \code{memploymentyes} is the deviation (effect) coded version of covariate \code{memployment},
generated with function \fct{contr.sum} by setting the contrasts argument of the factor variable,
i.e., \code{memploymentyes} contains of values $-1$, corresponding to `yes', and 1, `no'
respectively, likewise for covariates \code{genderfemale}, \code{urbanno}, \code{meducationno}
and \code{meducationprimary}. As mentioned in the introduction, functions $f_1$ and $f_2$ of
the continuous covariates \code{agechild} and \code{mbmi} are assumed to have a possibly nonlinear
effect on \code{stunting} and are therefore modeled with P-splines. Furthermore, the spatial effect
is decomposed into a structured effect $f_{str}$, modeled by a Gaussian Markov random field, and an
unstructured effect $f_{unstr}$, using a random effects term for the districts in Zambia.

The data for this analysis is provided in the \pkg{R2BayesX} package and can be loaded with
<<data-zambia, echo=TRUE, eval=TRUE>>=
data("ZambiaNutrition", package = "R2BayesX")
@
Since function $f_{str}$ is modeled by a Markov random fields term, \pkg{BayesX} needs information
about the district neighborhood structure, which e.g., is enclosed in the file
<<data-zambia-bnd, echo=TRUE, eval=TRUE>>=
data("ZambiaBnd", package = "R2BayesX")
@
The object \code{ZambiaBnd} has class \class{bnd} and is basically a \fct{list} of polygon
matrices, with $x$- and $y$-coordinates of the boundary points in the first and second column
respectively. With the information of the boundary file \pkg{BayesX} may compute an appropriate
adjacency matrix, allowing for a smoothly varying effect of the neighboring regions.
In addition, \class{bnd} objects can be used to calculate centroids of polygons to estimate
smooth bivariate effects of the resulting coordinates (e.g., using the \code{"geokriging"} option in
Section~\ref{sec:motivation}, also see Section~\ref{subsec:forest} for another example). There is a
generic plotting method implemented for objects of class \class{bnd}, which essentially calls
function \fct{plotmap}. E.g., a simple map, as shown in Figure~\ref{fig:zambia-simple-map}, of the
districts in Zambia is drawn by typing
<<plot-zambia-map-01, echo=TRUE, eval=FALSE>>=
plot(ZambiaBnd)
@
\begin{figure}[!t]
\setkeys{Gin}{width=0.46\textwidth}
\centering
<<plot-zambia-map-02, echo=FALSE, eval=TRUE, fig = TRUE, width=5, height=4, pdf=FALSE, png=TRUE>>=
par(mar = c(0, 0, 0, 0))
plot(ZambiaBnd, col = "lightgray")
@
\caption{\label{fig:zambia-simple-map} Example on childhood malnutrition: A simple map of the
districts in Zambia.}
\end{figure}
Having loaded the necessary files, the model \code{formula} is specified with
<<formula-zambia, echo=TRUE, eval=TRUE>>=
f <- stunting ~ memployment + urban + gender + meducation + sx(mbmi) + 
  sx(agechild) + sx(district, bs = "mrf", map = ZambiaBnd) + r(district)
@
As mentioned above, the structured spatial effect is now modeled as a Markov random field (option
\code{"mrf"}), while in Section~\ref{sec:motivation} we used the region centroids to model a smooth
spatial effect applying (geo)kriging. The model is then fitted using MCMC by calling
<<fit-zambia-model, echo=TRUE, eval=FALSE>>=
zm <- bayesx(f, family = "gaussian", method = "MCMC", iterations = 12000,
  burnin = 2000, step = 10, seed = 123, data = ZambiaNutrition)
@
<<cache-zambia-model, echo=FALSE, eval=TRUE>>=
if(file.exists("zambia-model.rda")) {
load("zambia-model.rda")
} else {
<<fit-zambia-model>>
save(zm, file = "zambia-model.rda")
}
@
Argument \code{iterations}, \code{burnin} and \code{step} set the number of iterations of the MCMC
simulation, the burnin period, which will be removed from the generated samples, and the step length
for which samples should be stored, i.e., if \code{step = 10}, every 10th sampled parameter will
be saved. In most applications 12000 iterations should be enough for a valid fit with sufficiently
small autocorrelations of stored parameters, at least in the model building stage. However, it is
crucial to inspect the sampled parameters and autocorrelation functions to check the
mixing behavior (see below). Moreover, it is generally advisable to specify a higher number of
iterations for the final model that appears in publications. Argument \code{seed} sets the state of
the random number generator in \pkg{BayesX} for exact reproducibility of the model fit.

After the model has been successfully fitted, summary statistics of the MCMC estimated model object
may be printed with
<<summary-zambia-model>>=
summary(zm)
@
which typically includes mean, standard deviation and quantiles of sampled linear effects, smooth
terms variances and random effects variances, as well as goodness of fit criteria and some other
information about the model. The estimated effects for covariates \code{agechild} and \code{mbmi}
may then be visualized with
<<zambia-agechild-mbmi-plot, echo=TRUE, eval=FALSE>>=
plot(zm, term = c("sx(mbmi)", "sx(agechild)"))
@
\begin{figure}[!t]
\setkeys{Gin}{width=0.46\textwidth}
\centering
<<zambia-mbmi, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 1.1))
plot(zm, term = "sx(mbmi)")
@
<<zambia-agechild, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 1.1))
plot(zm, term = "sx(agechild)")
@
\caption{\label{fig:zambia-agechild} Example on childhood malnutrition: Effect of the body mass
index of the child's mother and of the age of the child together with pointwise 80\% and 95\%
credible intervals.}
\end{figure}
and are shown in Figure~\ref{fig:zambia-agechild}. The interpretations of both terms are essentially
unchanged compared to the simpler model considered in Section~\ref{sec:motivation}:
The age of the child has a larger effect on stunting while mother's BMI could also be modeled
approprietly by a linear term.

A visual representation of the structured and unstructured spatial effect can be obtained
in two ways. Using the plain plot function
<<zambia-district-example-kde, echo=TRUE, eval=FALSE>>=
plot(zm, term = c("sx(district)", "r(district)"))
@
produces a kernel density estimator of the posterior mean of the effects, see Figure
\ref{fig:zambia-district-structured-unstructured-kde}.
\begin{figure}[!t]
\setkeys{Gin}{width=0.46\textwidth}
\centering
<<zambia-district-structured-kde, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.4, 1.1))
plot(zm, term = "sx(district)", map = FALSE, main = "")
@
<<zambia-district-unstructured-kde, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.4, 1.1))
plot(zm, term = "r(district)", map = FALSE, main = "")
@
\caption{\label{fig:zambia-district-structured-unstructured-kde} Example on childhood malnutrition:
Kernel density estimates of the mean of the structured, left panel, and the unstructured spatial
effect, right panel respectively.}
\end{figure}
The kernel densities reveal the general form of the random effects distributions which are assumed
to follow a Gaussian distribution. The range of the estimated random spatial effect is much smaller
than the range of the structured spatial effect, indicating that model fit improvement by including
random effects that account for unobserved spatial heterogeneity of the regions in Zambia, is
relatively low. This is also supported by the comparatively low variance estimate of the random
effects term given in the model summary above.

To view the
spatial structure of the correlated effect we have to use the plot function in combination with the
boundary object \code{ZambiaBnd}:
<<zambia-district-example, echo=TRUE, eval=FALSE>>=
plot(zm, term = "sx(district)", map = ZambiaBnd)
@
The generated map effect plot is shown in Figure~\ref{fig:zambia-district-structured-unstructured}.
\begin{figure}[!t]
\setkeys{Gin}{width=0.46\textwidth}
\centering
<<zambia-district-structured, echo=FALSE, fig=TRUE, width=5, height=4, pdf=FALSE, png=TRUE>>=
par(mar = c(0, 0, 0, 0))
plot(zm, term = "sx(district)", map = ZambiaBnd, swap = TRUE)
@
<<zambia-district-unstructured-samescale, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(0, 0, 0, 0))
plot(zm, term = "r(district)", map = ZambiaBnd, swap = TRUE,
  range = c(-0.32, 0.32), lrange = c(-0.32, 0.32))
@
\caption{\label{fig:zambia-district-structured-unstructured} Example on childhood malnutrition:
Estimated mean effect of the structured spatial effect (left panel), together with the unstructured
spatial effect using the color and legend scaling of the structured effect (right panel).}
\end{figure}
As a default the districts of Zambia are colored in a symmetrical range within the estimated
$\pm \max(|\mathit{\text{posterior mean}}|)$ of the corresponding effect.
In many situations the visual impression of the colored map is
problematic. This is primarily the case if there are some districts with extraordinarily high
posterior means compared to the rest of the districts. Then the map is dominated by the colors of
these outlying districts. A more informative map may be obtained by restricting the range of the
plotting area using the range option. For the Zambia data the corresponding random effects are
comparably symmetric and without outlying districts such that the plot function with default options
produces fairly informative maps. To demonstrate the range option we draw the unstructered random
effect and the legend range within the same range as the structured random effect
<<zambia-district-example-redraw, echo=TRUE, eval=FALSE>>=
plot(zm, term = "r(district)", map = ZambiaBnd, 
  range = c(-0.32, 0.32), lrange = c(-0.32, 0.32))
@ %$
The resulting map is also shown in Figure~\ref{fig:zambia-district-structured-unstructured} (right 
panel). Using for both the structured and the unstructered effect the same scale is useful for 
comparison. In most cases one of the two effects clearly dominates the other. In our case the 
structured spatially correlated effect clearly exceeds the unstructured effect.

For MCMC post estimation diagnosis, it is also possible to extract sampling paths of parameters with
function \fct{samples}, or to plot the samples directly. For instance, coefficient sampling paths
for term \code{sx(mbmi)} are displayed with
<<zambia-mbmi-coef-samples, echo=TRUE, eval=FALSE, fig=FALSE>>=
plot(zm, term = "sx(mbmi)", which = "coef-samples")
@
see Figure~\ref{fig:zambia-mbmi-coef-samples}. The plot of sampled parameters should ideally show
white noise, i.e., more or less uncorrelated samples that show no particular pattern. In our case the
samples are exactly as they should be. 
\begin{figure}[!t]
\setkeys{Gin}{width=\textwidth}
\centering
<<zambia-mbmi-coef-samples-do, echo=FALSE, fig=TRUE, width=7, height=8>>=
par(oma = c(0.01, 0.01, 0.01, 0.01))
plot(zm, term = "sx(mbmi)", which = "coef-samples", main = NA)
@
\caption{\label{fig:zambia-mbmi-coef-samples} Example on childhood malnutrition: Sampling paths of
the first 12 coefficients of term \code{sx(mbmi)}.}
\end{figure}
In addition, autocorrelation functions may be drawn, e.g., for the variance samples of term
\code{sx(mbmi)}, by typing
<<zambia-autocorr-01, echo=TRUE, eval=FALSE>>=
plot(zm, term = "sx(mbmi)", which = "var-samples", acf = TRUE)
@
The maximum autocorrelation of all sampled parameters in the model are displayed with
<<zambia-autocorr-02, echo=TRUE, eval=FALSE>>=
plot(zm, which = "max-acf")
@
\begin{figure}[!t]
\setkeys{Gin}{width=0.49\textwidth}
\centering
<<zambia-autocorr-03, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 1.1))
plot(zm, term = "sx(mbmi)", which = "var-samples", acf = TRUE, main = "")
@
<<zambia-autocorr-04, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 1.1))
plot(zm, which = "max-acf", main = "")
@
\caption{\label{fig:zambia-autocorr} Example on childhood malnutrition: Autocorrelation function
of the samples of the variance parameter of term \code{sx(mbmi)} (left panel)
and maximum autocorrelation of all parameters of the model (right panel).}
\end{figure}
Autocorrelations for all lags should be close to zero as is mostly the case in our example. See
Figure~\ref{fig:zambia-autocorr}, for the autocorrelation plots. The plot of maximum autocorrelations over all
model parameters suggests to use a larger number of iterations in a final run (e.g., 22000 ore even 32000 iterations). 

In some situations problems may occur during processing of the \pkg{BayesX} binary, that are not
automatically detected by the main model fitting function \fct{bayesx}. Therefore the user may
inspect the log-file generated by the binary in two ways: Setting the option \code{verbose = TRUE}
in \fct{bayesx.control} will print all information produced by \pkg{BayesX} simultaneously at 
runtime. The option is especially helpful if \pkg{BayesX} fails in the estimation of the model. Another way to obtain the 
log-file is to use function \fct{bayesx\_logfile} if \pkg{BayesX} successfully finished processing. 
In this example the log-file may be printed with
\begin{Schunk}
\begin{Sinput}
R> bayesx_logfile(zm)
\end{Sinput}
\begin{Soutput}
> bayesreg b
> map ZambiaBnd
> ZambiaBnd.infile using /tmp/Rtmpa3Z6WF/bayesx/ZambiaBnd.bnd
NOTE: 57 regions read from file /tmp/Rtmpa3Z6WF/bayesx/ZambiaBnd.bnd
> dataset d
> d.infile using /tmp/Rtmpa3Z6WF/bayesx/bayesx.estim.data.raw
NOTE: 14 variables with 4847 observations read from file
/tmp/Rtmpa3Z6WF/bayesx/bayesx.estim.data.raw

> b.outfile = /tmp/Rtmpa3Z6WF/bayesx/bayesx.estim
> b.regress stunting = mbmi(psplinerw2,nrknots=20,degree=3) +
    agechild(psplinerw2,nrknots=20,degree=3) + district(spatial,map=ZambiaBnd) +
    district(random) + memploymentyes + urbanno + genderfemale + meducationno +
    meducationprimary, family=gaussian iterations=12000 burnin=2000 step=10
    setseed=123 predict using d
NOTE: no observations for region 11
NOTE: no observations for region 84
NOTE: no observations for region 96


BAYESREG OBJECT b: regression procedure

GENERAL OPTIONS:

  Number of iterations:  12000
  Burn-in period:        2000
  Thinning parameter:    10


RESPONSE DISTRIBUTION:

  Family: Gaussian
  Number of observations: 4847
  Number of observations with positive weights: 4847
  Response function: identity
  Hyperparameter a: 0.001
  Hyperparameter b: 0.001
\end{Soutput}
\end{Schunk}
To simplify matters only a fragment of the log-file is shown in the above. The log-file typically
provides information on the used data, model specifications, algorithms and possible error
messages.


\subsection{Forest health dataset: Analysis with REML} \label{subsec:forest}

The dataset on forest health comprises information on the defoliation of beech trees, which serves
as an indicator of overall forest health here. The data were collected annually from 1980 to 1997
during a project of visual inspection of trees around Rothenbuch, Germany, see
\citet{R2BayesX:Goettlein+Pruscha:1996}, and is discussed in detail in
\citet{R2BayesX:Fahrmeir+Kneib+Lang:2009}. In this example, the percentage rate of defoliation of
each tree is aggregated into three ordinal categories, which are modeled in terms of covariates
characterizing the stand and site of a tree. In addition, temporal and spatial information is
available, see also Table~\ref{tab:forest}.
\begin{table}[t!]
\centering
\begin{tabular}{lp{10cm}}
\hline
Variable           & Description \\ \hline
\code{id}          & Tree location identification number. \\
\code{year}        & Year of census. \\
\code{defoliation} & Percentage of tree defoliation in three ordinal
                     categories: `< 12.5\%', `12.5\% $\leq$ defoliation < 50\%',
                     `$\geq$ 50\%'. \\
\code{age}         & Age of stands in years. \\
\code{canopy}      & Forest canopy density in percent. \\
\code{inclination} & Slope inclination in percent. \\
\code{elevation}   & Elevation (meters above sea level). \\
\code{soil}        & Soil layer depth in cm. \\
\code{ph}          & Soil pH at 0--2cm depth. \\
\code{moisture}    & Soil moisture level with categories `moderately dry', `moderately moist' and
                     `moist or temporarily wet'. \\
\code{alkali}      & Proportion of base alkali-ions with categories `very low', `low', `high' and
                     `very high'. \\
\code{humus}       & Humus layer thickness in cm. \\
\code{stand}       & Stand type with categories `deciduous' and `mixed'. \\
\code{fertilized}  & Fertilization applied with categories `yes' and `no'. \\ \hline
\end{tabular}
\caption{\label{tab:forest} Variables in the forest health dataset.}
\end{table}

Similar to \citet{R2BayesX:Fahrmeir+Kneib+Lang:2009}, we start with a threshold model and cumulative
logit link, with $P(\texttt{defoliation}_{it} \leq r)$ of tree $i$ at time $t$, for response
category $r = 1,2$, and the additive predictor
\begin{eqnarray*}
\eta_{it}^{(r)} &=& f_1(\texttt{age}_{it}) + f_2(\texttt{inclination}_{i}) +
  f_3(\texttt{canopy}_{it}) + f_4(\texttt{year}) + f_5(\texttt{elevation}_{i}) +
  \mathbf{x}_{it}^{\top}\boldsymbol{\gamma}
\end{eqnarray*}
where  $f_1, \dots, f_5$  are possibly nonlinear smooth functions of the continuous covariates
and $\mathbf{x}_{it}^{\top}\boldsymbol{\gamma}$ comprises covariates with parametric
effects using deviation (effect) coding for factor covariates.

To estimate the model within \proglang{R} the data is loaded and the model formula specified with
<<forest-model-formula-01, echo=TRUE, eval=TRUE>>=
data("ForestHealth", package = "R2BayesX")
f <- defoliation ~  stand + fertilized + humus + moisture + alkali + ph +
  soil + sx(age) + sx(inclination) + sx(canopy) + sx(year) + sx(elevation)
@
The covariates entering nonlinearly are again modeled by P-splines. The model is then fitted
applying REML by assigning a cumulative logit model and calling
<<fit-forest-model-01, echo=TRUE, eval=FALSE>>=
fm1 <- bayesx(f, family = "cumlogit", method = "REML",
  data = ForestHealth)
@
<<fit-forest-model-02, echo=FALSE, eval=FALSE>>=
data("BeechBnd", package = "R2BayesX")
fm2 <- update(fm1, . ~ . + sx(id, bs = "gs", map = BeechBnd))
@
<<cache-forest-model, echo=FALSE, eval=TRUE>>=
if(file.exists("forest-model.rda")) {
load("forest-model.rda")
} else {
<<fit-forest-model-01>>
<<fit-forest-model-02>>
save(fm1, fm2, file = "forest-model.rda")
}
@
After the estimation process has converged, the estimated effects of the nonparametric modeled terms
may be visualized by
<<fit-forest-model-01-plots, echo=TRUE, eval=FALSE>>=
plot(fm1, term = c("sx(age)", "sx(inclination)", "sx(canopy)", "sx(year)",
  "sx(elevation)"))
@
\begin{figure}[!ht]
\setkeys{Gin}{width=0.46\textwidth}
\centering
<<forest-no-spatial-age, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 2.1))
plot(fm1, term = "sx(age)")
@
<<forest-no-spatial-inclination, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 2.1))
plot(fm1, term = "sx(inclination)")
@
\\[2ex]

<<forest-no-spatial-canopy, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 2.1))
plot(fm1, term = "sx(canopy)")
@
<<forest-no-spatial-year, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 2.1))
plot(fm1, term = "sx(year)")
@
\\[2ex]

<<forest-no-spatial-elevation, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 2.1))
plot(fm1, term = "sx(elevation)")
@
\caption{\label{fig:forest-no-spatial} Forest damage: Estimates of nonparametric effects including
80\% and 95\% point-wise confidence intervals of the model without the spatial effect.}
\end{figure}
The results are shown in Figure~\ref{fig:forest-no-spatial} and appear to be rather unintuitive.
In particular, the effect of the covariate \code{age} on \code{defoliation} seems to be non-monotonic
with low defoliation levels for both younger and older trees. Similarly, the effect of \code{elevation}
is very non-monotonic with high defoliation for both low and high elevations. Finally, the
extremely wiggly estimate of \code{inclination} is hardly interpretable. Therefore,
\citet{R2BayesX:Goettlein+Pruscha:1996} extend the model by a spatial effect, which is modeled by a
two dimensional geospline term of the tree locations. The tree $x$- and $y$-coordinates are
calculated by the centroid positions of tree polygons given by the boundary map file \code{BeechBnd}.
We can update the  model by adding a \code{"gs"} effect:
<<fit-forest-model-02-show, echo=TRUE, eval=FALSE>>=
<<fit-forest-model-02>>
@
Taking a look at model information criteria
<<summary-forest-model, echo=TRUE, eval=TRUE>>=
BIC(fm1, fm2)
GCV(fm1, fm2)
@
clearly indicates a better fit by modeling the spatial effect of tree locations. The summary
statistics for both models gives:
<<summary-forest-model>>=
summary(fm1)
summary(fm2)
@
Most of the parametric modeled terms in the second model now have an insignificant effect on tree
defoliation, with similar findings for covariates \code{inclination} and \code{elevation} (where the pointwise 95\%
credible intervals cover the zero line). However,
the estimate of the \code{age} effect seems to be improved in terms of monotonicity, see
Figure~\ref{fig:forest-spatial-nonpara}.

\begin{figure}[t!]
\setkeys{Gin}{width=0.46\textwidth}
\centering
<<forest-spatial-inclination, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 2.1))
plot(fm2, term = "sx(inclination)")
@
<<forest-spatial-elevation, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 2.1))
plot(fm2, term = "sx(elevation)")
@
\\[2ex]

<<forest-spatial-age, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.1, 2.1))
plot(fm2, term = "sx(age)")
@
\caption{\label{fig:forest-spatial-nonpara} Forest damage: Estimated effects of covariates
\code{inclination}, \code{elevation} and \code{age}, including 80\% and 95\% point-wise confidence
intervals, of the model including the spatial effect.}
\end{figure}

A kernel density plot of the estimated spatial effect is then obtained by 
<<forest-spatial-id, echo=TRUE, eval=FALSE>>=
plot(fm2, term = "sx(id)", map = FALSE)
@
\begin{figure}[p!]
\setkeys{Gin}{width=0.65\textwidth}
\centering
\setkeys{Gin}{width=0.46\textwidth}
<<forest-spatial-id-restrict-kde, echo=FALSE, fig=TRUE, width=5, height=4>>=
par(mar = c(4.1, 4.1, 0.4, 1.1))
plot(fm2, term = "sx(id)", map = FALSE, main = "")
@ 
\\[2ex]

\setkeys{Gin}{width=0.65\textwidth}
\centering
<<forest-spatial-id, echo=FALSE, fig=TRUE, width=7.3, height=4.5, pdf=FALSE, png=TRUE>>=
par(mar = c(0.1, 0.1, 0.1, 0.1))
plot(fm2, term = "sx(id)", map = BeechBnd,
  height = 0.24, width = 0.41)
@
\\[2ex]

<<forest-spatial-id-restrict, echo=FALSE, fig=TRUE, width=7.3, height=4.5, pdf=FALSE, png=TRUE>>=
par(mar = c(0.1, 0.1, 0.1, 0.1))
plot(fm2, term = "sx(id)", map = BeechBnd,
  height = 0.24, width = 0.41, range = c(-3, 3))
@
\caption{\label{fig:forest-spatial-kde} Forest damage: Kernel density estimate of the spatial 
  effect (top panel), together with a map effect plot (middle panel), and map effect plot
  with modified color scaling (bottom panel). In the latter plot, the maximum shading is
  attained at $-3$ and $3$, respectively, corresponding to the
  10\% and 90\% quantiles of the kernel density estimate of the effect.}
\end{figure}
The effect may also be visualized either using a 3d perspective plot, an image/contour plot or a map 
effect plot using the boundary file \code{BeechBnd} with
<<forest-spatial-id, echo=TRUE, eval=FALSE>>=
plot(fm2, term = "sx(id)", map = BeechBnd)
@
Both the kernel density and map effect plot are shown in the first two panels of
Figure~\ref{fig:forest-spatial-kde}. In this example the coloring of the plot is strongly influenced
by a few very high and low values. Therefore, it is helpful to restrict the color range e.g., using
the maximum shading for all absolute effects in excess of 3 (which roughly corresponds to the
absolute values of the 10\% and 90\%  quantiles of the kernel density estimate of the effect).
The resulting map in the bottom panel of Figure~\ref{fig:forest-spatial-kde} is created by:
<<forest-spatial-id-restrict, echo=TRUE, eval=FALSE>>=
plot(fm2, term = "sx(id)", map = BeechBnd, range = c(-3, 3))
@
Trimming the color range of the plot now leads to a better representation of the effect.

In summary, the results identify a strong influence of the spatial effect on the overall model
fit, indicating that a clear splitting of location-specific covariates and the spatial effect is
hardly possible in this example.


\subsection{Childhood malnutrition in Zambia: Analysis with STEP} \label{subsec:zambia-step}

To illustrate the implemented methodology for simultaneous selection of variables and smoothing
parameters, we proceed with the dataset on malnutrition in Zambia of
Section~\ref{subsec:zambia}. In this example, the structured additive
predictor~(\ref{eqn:zambia-eta}) contains two continuous covariates \code{mbmi} and \code{agechild},
that are assumed to have a possibly nonlinear effect on the response \code{stunting} and are modeled
with P-splines. However, to assess whether this is really necessary the corresponding linear effect is also
considered using the selection algorithm in \pkg{BayesX}. Additionally, for each variable and
function, the implemented procedures decide if a term is included or removed from the model. To
estimate the model applying the option \code{method = "STEP"}, we use the same  model formula of
Section~\ref{subsec:zambia} and call
<<fit-zambia-model-step-01, echo=TRUE, eval=FALSE>>=
f <- stunting ~ memployment + urban + gender +
  sx(meducation, bs = "factor") + sx(mbmi) + sx(agechild) +
  sx(district, bs = "mrf", map = ZambiaBnd) + r(district)
zms <- bayesx(f, family = "gaussian", method = "STEP",
  algorithm = "cdescent1", startmodel = "empty", seed = 123,
  data = ZambiaNutrition)
@
<<fit-zambia-model-step-02, echo=FALSE, eval=FALSE>>=
zmsccb <- bayesx(f, family = "gaussian", method = "STEP",
  algorithm = "cdescent1", startmodel = "empty", CI = "MCMCselect",
  iterations = 10000, step = 10, seed = 123, data = ZambiaNutrition)
@
<<cache-zambia-model-step, echo=FALSE, eval=TRUE>>=
if(file.exists("zambia-model-step.rda")) {
load("zambia-model-step.rda")
} else {
data("ZambiaNutrition", "ZambiaBnd", package = "R2BayesX")
<<fit-zambia-model-step-01>>
<<fit-zambia-model-step-02>>
save(zms, zmsccb, file = "zambia-model-step.rda")
}
@
where argument \code{algorithm} chooses the selection algorithm and \code{startmodel} the start
model for variable selection, see also Table~\ref{tab:control} for all possible options. Usually the selected
final model is unaffected by the selection algorithm and startmodel. However, it is generally of interest to 
assess the dependence of results on the selction algorithm and the startmodel. The
summary statistics of the final selected model are then provided with
<<zambia-model-step-summary, echo=TRUE, eval=TRUE>>=
summary(zms)
@
Thus, the results are similar to those from model \code{zm} in Section~\ref{subsec:zambia}.
However, the variable \code{memployment} is removed from the model and variable \code{mbmi} is
modeled by a linear effect. 

By default, the columns \code{sd}, \code{2.5\%}, \code{50\%} and \code{97.5\%} from a \code{"STEP"}
fit contain no values, likewise for the estimated random and smooth effects. The posterior quantiles
may be computed if argument \code{CI} in function \fct{bayesx.control} is specified. E.g.,
conditional confidence bands can be calculated conditional on the selected model, i.e., they are
computed for selected variables and functions only. The computation of conditional confidence bands
is based on an MCMC-algorithm subsequent to the selection procedure.  For the selection of a model
with a subsequent computation of conditional confidence bands the user may type
<<fit-zambia-model-step-02-show, echo=TRUE, eval=FALSE>>=
<<fit-zambia-model-step-02>>
@
which results in the following summary
<<zambia-model-step-summary-2, echo=TRUE, eval=TRUE>>=
summary(zmsccb)
@
It is also possible to obtain unconditional confidence bands by setting \code{CI = "MCMCbootstrap"},
which additionally considers the uncertainty due to model selection.

Another variation of this model would be to start from a \code{"userdefined"} instead of an \code{"empty"}
\code{startmodel} (see also Table~\ref{tab:control} for further options). In the \code{"userdefined"} case
Besides the default of an \code{"empty"} \code{startmodel}, it may be reasonable to start with a
the initial degrees of freedom (complexity or roughness) in the search for the nonlinearly modeled
terms can be supplied. For example, the starting values for the degrees of freedom of
the P-spline, spatial and random effect terms can be specified via
<<fit-zambia-model-step-05, echo=TRUE, eval=FALSE>>=
f <- stunting ~ memployment + urban + gender +
  sx(meducation, bs = "factor") + sx(mbmi, dfstart = 2) + 
  sx(district, bs = "mrf", map = ZambiaBnd, dfstart = 5) + 
  r(district, xt = list(dfstart = 5)) + sx(agechild, dfstart = 2)
@
The model is then fitted by
<<fit-zambia-model-step-06, echo=TRUE, eval=FALSE>>=
zmsud <- bayesx(f, family = "gaussian", method = "STEP",
  algorithm = "cdescent1", startmodel = "userdefined", CI = "MCMCselect",
  iterations = 10000, step = 10, seed = 123, data = ZambiaNutrition)
@
which actually produces the model output of the first model (\code{zms}) again.


\section{Summary}\label{sec:conclusion}

\fixme{still to do}

\section*{Acknowledgments}

\fixme{who to mention here? rest of BayesX team? Fabian for testing? any projects/services?}


\bibliography{R2BayesX}

\clearpage


\begin{appendix}

\section[BayesXsrc: Packaging the BayesX C++ sources for R]{\pkg{BayesXsrc}: Packaging the \pkg{BayesX} \proglang{C++} sources for \proglang{R}}
\label{appendix:BayesXsrc}

\pkg{BayesX} was originally developed under the Borland \proglang{C++} compiler and
is distributed as a Windows application with a \proglang{Java}-based user interface.
Since version~2.0, it is also offers a command line version 
comprising the interpreter and modules for computations. The sources have 
been modified to be compliant with the GNU Compiler Collection (GCC), and the
software was ported to run on Linux, Mac OS~X, Windows and several BSDs.

Our objective with the \proglang{R}~package \pkg{BayesXsrc} is to offer \proglang{R}~users a 
convenient way to download, build, and install the open-source \pkg{BayesX} 
software as if this were an ordinary \proglang{R}~package, and for offering
prebuilt binary versions of \pkg{BayesX} through the CRAN build servers
for major \proglang{R}~platforms.

To accomplish this goal, \pkg{BayesXsrc} comes with a tiny \proglang{R} package hull,
within which the \pkg{BayesX} sources for the command line version are embedded.
In order to compile the \pkg{BayesX} sources with the \proglang{R} build system
(e.g., via \code{R CMD INSTALL}), \code{Makefile}s under \code{src/} are utilized
to compile the sources stored at \code{src/bayesxsrc}.
The current source tree of \pkg{BayesX} requires a slightly different setting of
compile flags for Windows which is achieved by using the two standard locations for 
\proglang{R} \code{Makefile}s: \code{src/Makefile.win} for Windows and \code{src/Makefile} otherwise.
Since \proglang{R}~2.13.1 the package installation was enhanced to support non-standard
installation of compiled code via an \proglang{R} installation script. If an
\proglang{R} script \code{src/install.libs.R} is found, it will be executed
after successful compilation.
We make use of this feature to copy the binary executable to the
package installation directory in an architecture-specific subfolder
to support multi-architecture installations using \proglang{R} as a cross-platform
portable install shell:
%
\begin{Code}
binary <- if(WINDOWS) "BayesX.exe" else "BayesX"
if(file.exists(binary)) {
  libarch <- if (nzchar(R_ARCH)) paste("libs", R_ARCH, sep = "") else "libs"
  dest <- file.path(R_PACKAGE_DIR, libarch)
  dir.create(dest, recursive = TRUE, showWarnings = FALSE)
  file.copy(binary, dest, overwrite = TRUE)
}
\end{Code}
%
Since the executable exists in a designated location within the 
installed \pkg{BayesXsrc} package, we can run the 
command line version from within \proglang{R} via a single front-end function \fct{run.bayesx}.

Note that the package hull of \pkg{BayesXsrc} (without \code{inst/bayesxsrc}) is maintained
in a subversion (SVN) repository on \proglang{R}-Forge
(at \url{https://R-Forge.R-project.org/projects/bayesr/}, along with \pkg{R2BayesX}).
It enables simple creation of development snapshots of \pkg{BayesX}: The \pkg{BayesXsrc} sources in the SVN
provide a top-level \code{bootstrap.sh} shell script that pulls the \pkg{BayesX} sources from
its SVN repository (at \url{http://svn.gwdg.de/svn/bayesx/}) and stores them in the
\code{src/bayesxsrc} directory. Subsequently, the \proglang{R}~source package for \pkg{BayesXsrc}
can be created as usual via \code{R CMD build}.

Although we do not effectively distribute an \proglang{R} package in the usual sense, 
we use the \proglang{R} package system as a cross-platform build system.
The installation via an \proglang{R} package is an attractive alternative, in particular
for software that aims to be embedded to \proglang{R}.  
Potential support for distribution and delivery of self-contained
software in form of sources and prebuilt  binaries via CRAN is very attractive 
to end users but also to smaller development teams (like us) that would 
otherwise have no resources for multi-platform builds and tests.

\section[Options for the plot() method]{Options for the \fct{plot} method}
\label{appendix:plotting}

\begin{table}[b!]
\centering
\begin{tabular}{p{2.3cm}p{11.8cm}}
\hline
Argument & Description \\ \hline
\code{term} & The term that should be plotted, either an integer or a character, e.g.,
              \code{term = "sx(x)"}. \\
\code{which} & Choose the type of plot that should be drawn, possible options are: \code{"effect"},
    \code{"coef-samples"}, \code{"var-samples"}, \code{"intcpt-samples"}, \code{"hist-resid"}, 
    \code{"qq-resid"}, \code{"scatter-resid"}, \code{"scale-resid"}, \code{"max-acf"}. Argument 
    \code{which} may also be specified as integer, e.g., \code{which = 1}. The first three arguments 
    are all model term-specific. For the residual model diagnostic plot options \code{which} 
    may be set with \code{which = 5:8}. \\ \hline
\code{residuals} & If set to \code{TRUE}, partial residuals may also be plotted if available. \\
\code{rug} & If set to \code{TRUE}, a \fct{rug} is added to the plot. \\
\code{jitter} & If set to \code{TRUE}, a \fct{jitter}ed \fct{rug} is added to the plot. \\ \hline
\code{col.surface} & The color of the surface, may also be a function, e.g.,
    \code{col.surface = heat.colors}. \\
\code{grid} & The grid size of the surface(s). \\
\code{image} & If set to \code{TRUE}, an \fct{image.plot} is drawn. \\
\code{contour} & If set to \code{TRUE}, a \fct{contour} plot is drawn. \\ \hline
\code{map} & The map to be plotted, the map object must be a list of matrices with first column
          indicating the $x$-coordinate and second column the $y$-coordinate each, see also
          function \fct{polygon}. \\
\code{legend} & If set to \code{TRUE}, a legend will be shown. \\
\code{range} & Specify the range of values the plot should be generated for, e.g., only values
           between $-2$ and 2 are of interest then \code{range = c(-2, 2)}. \\ \hline
\code{color} & The colors for the legend, may also be a function, e.g.,
           \code{colors = heat.colors}. \\
\code{pos} & The position of the legend, either a numeric vector, e.g., \code{pos = c(0.1, 0.2)}
          will add the legend at the 10\% point in the $x$-direction and at the 20\% point in the
          $y$-direction of the plotting window, may also be negative, or one of the following:
          \code{"bottomleft"}, \code{"topleft"}, \code{"topright"} or \code{"bottomright"}. Using
          function \fct{plotmap} option \code{"right"} is also valid. \\
\code{lrange} & Specifies the range of the legend. \\
\code{symmetric} & If set to \code{TRUE}, a symmetric legend will be drawn corresponding to the
          $\pm \max(|x|)$ of values $x$ that are used for plotting. \\ \hline
\end{tabular}
\caption{\label{tab:plotting} Most important arguments of the \fct{plot} method for \class{bayesx}
objects. The first block describes arguments of the \fct{plot} method itself, subsequent blocks
arguments that are passed to \fct{plot2d}, \fct{plot3d}, \fct{plotmap}, and
\fct{colorlegend}, respectively.}
\end{table}

Objects of class \class{bayesx} returned either from function \fct{bayesx} or
\fct{read.bayesx.output} have a method for the \fct{plot} generic. Depending on the structure of the
\class{bayesx} object, the method identifies the various types of inherent model terms and applies
one of the following implemented plotting functions: \fct{plot2d}, \fct{plot3d} or \fct{plotmap}.
Using the method without further specifications will produce a plot of all estimated effects.
For individual effect plots argument \code{term} is used. For MCMC estimated models argument
\code{which} is useful to inspect sampling paths of coefficients, but also to view basic residual
diagnostic plots. To build map effect plots using \fct{plotmap}, a map needs to be supplied to
argument \code{map}. The \code{map} must be an object of \class{bnd} or
\class{SpatialPolygonsDataFrame}. Per default, similar to 2d plots, map effect plots are colored
using a diverging color legend where the \code{range} is set \code{symmetric}al, e.g.\ according to
the $\pm \, \max(|\text{posterior mean}|)$ of the effect. In this setting it is easier to distinguish
between regions of large and no influence. The most important options of the plotting method are
shown in Table~\ref{tab:plotting}, for a detailed description of all available arguments and
options please see documentation of function \fct{plot.bayesx}, \fct{plot2d}, \fct{plot3d},
\fct{plotmap} and \fct{colorlegend}.  

\end{appendix}


\end{document}
