---
title: "Generalized Linear Models (+)"
output:
  html_document:
    toc: true
    toc_float: true
    theme: flatly
bibliography: bamlss.bib
nocite: '@bamlss:Umlauf+bamlss:2018'
vignette: >
  %\VignetteIndexEntry{Model Terms}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteDepends{bamlss}
  %\VignetteKeywords{distributional regression, GLM, big data}
  %\VignettePackage{bamlss}
---

```{r preliminaries, echo=FALSE, message=FALSE}
library("bamlss")
set.seed(123)
```

## Intro

The _bamlss_ package is perfectly suitable for estimating (Bayesian) generalized linear 
models (GLM) and provides infrastructures for the estimation using very large data sets,
too.  Within the main model fitting function `bamlss()`, the possible `family` 
specifications for fitting GLMs are:

* `"gaussian"` or `gaussian_bamlss()`,
* `"beta"` or `beta_bamlss()`,
* `"binomial"` or `binomial_bamlss()`,
* `"gamma"` or `gamma_bamlss()`,
* `"poisson"` or `poisson_bamlss()`.

In addition, there is a wrapper function for the family objects provided by the _gamlss_
package [@bamlss:Stasinopoulos+Rigby:2018], so in principle all _gamlss_ families can be used by
just passing them to the `family` argument in the `bamlss()` function (see also the
[count data regression example](#countreg)).

First, we illustrate how  to fit standard GLMs and how to do inference using the _bamlss_ 
framework. Aftwards, we show how to estimate GLMs using very large data set.

## Logit Model

This example is taken from the _AER_ package
[@bamlss:Kleiber+Zeileis:2018; @bamlss:Kleiber+Zeileis:2008] and is about labor force 
participation (yes/no) of women in Switzerland 1981. The data can be loaded with
```{r}
data("SwissLabor", package = "AER")
print(head(SwissLabor))
```
The data frame contains of 872 observations on 7 variables, where some of them might have
a nonlinear influence on the response labor `participation`. Now, a standard Bayesian 
binomial logit model can be fitted with
```{r, echo=FALSE, message=FALSE, results='hide'}
if(!file.exists("figures/SwissLabor.rda")) {
  f <- participation ~ income + age + education + youngkids + oldkids + foreign + I(age^2)
  set.seed(123)
  b <- bamlss(f, family = "binomial", data = SwissLabor,
    n.iter = 12000, burnin = 2000, thin = 10)
  save(b, file = "figures/SwissLabor.rda")
} else {
  load("figures/SwissLabor.rda")
}
```
```{r, eval=FALSE}
## First, set the seed for reproducibly.
set.seed(123)

## Model formula.
f <- participation ~ income + age + education + youngkids + oldkids + foreign + I(age^2)

## Estimate model.
b <- bamlss(f, family = "binomial", data = SwissLabor,
  n.iter = 12000, burnin = 2000, thin = 10)
```
Note, to capture nonlinearities, a quadratic term for variable `age` is added to the model. The model summary gives
```{r}
summary(b)
```
which suggests "significant" effects for all covariates, since there are no zeros within
the 95% credible intervals. Before we proceed, we usually do some convergence checks of
the MCMC chains using traceplots.
```{r, eval=FALSE}
plot(b, which = "samples")
```
```{r, fig.width = 9, fig.height = 5, fig.align = "center", echo = FALSE, dev = "png", results = 'hide', message=FALSE}
plot(b$samples[, c("pi.p.(Intercept)", "pi.p.income")])
```
The plots indicate convergence of the MCMC chains, i.e., there is no visible trend in the
MCMC chains and very low autocorrelation suggest i.i.d. sampling from the posterior
distribution. Note that the function call would show all traceplots, however, for 
convenience we only show the plots for the intercept and variable `income`.

The estimated regression coefficients can also be extracted using the `coef()` method
```{r}
## Extract posterior mean.
coef(b, FUN = mean)

## Or use any other function on the samples.
coef(b, FUN = function(x) { quantile(x, prob = c(0.025, 0.975)) })
```
(there is also a `confint()` method). The naming convention of the regression coefficients 
might first seem a bit atypical, it is based on the idea that a _bamlss_ family/response 
distribution can have more than just one distributional parameter, as well as 
linear and/or nonlinear model terms. To explain, `pi` is the name of the distributional 
parameter in the `binomial_bamlss()` family and `p` stands for parametric terms, i.e.,
there would also be a `s` for smooth terms if they are part of the model.

Model predictions on the probability scale can be obtained by the predict method (see also
function `predict.bamlss()`).
```{r}
## Create some newdata for prediction, note that
## factors need to be fully specified (this will be changed soon).
nd <- data.frame(income = 11, age = 3.3,
  education = 12, youngkids = 1, oldkids = 1,
  foreign = factor(1, levels = 1:2, labels = c("no", "yes")))

## Predicted probabilities.
predict(b, newdata = nd, type = "parameter")
nd$foreign <- factor(2, levels = 1:2, labels = c("no", "yes"))
predict(b, newdata = nd, type = "parameter")
```
To visualize the effect of age on the probability we can do the following:
```{r, eval=FALSE}
## Predict effect of age including 95% credible intervals and plot.
nd <- data.frame(income = 11, age = seq(2, 6.2, length = 100),
  education = 12, youngkids = 1, oldkids = 1,
  foreign = factor(1, levels = 1:2, labels = c("no", "yes")))

nd$p.no <- predict(b, newdata = nd, type = "parameter", FUN = c95)
nd$foreign <- factor(2, levels = 1:2, labels = c("no", "yes"))
nd$p.yes <- predict(b, newdata = nd, type = "parameter", FUN = c95)

plot2d(p.no ~ age, data = nd, ylab = "participation",
  ylim = range(c(nd$p.no, nd$p.yes)), lty = c(2, 1, 2))
plot2d(p.yes ~ age, data = nd, col.lines = "blue", add = TRUE,
  lty = c(2, 1, 2))
legend("topright", c("foreign yes", "foreign no"), lwd = 1,
  col = c("blue", "black"))
```
```{r, fig.width = 5, fig.height = 5, fig.align = "center", echo = FALSE, dev = "png", results = 'hide', message=FALSE}
nd <- data.frame(income = 11, age = seq(2, 6.2, length = 100),
  education = 12, youngkids = 1, oldkids = 1,
  foreign = factor(1, levels = 1:2, labels = c("no", "yes")))

nd$p.no <- predict(b, newdata = nd, type = "parameter", FUN = c95)
nd$foreign <- factor(2, levels = 1:2, labels = c("no", "yes"))
nd$p.yes <- predict(b, newdata = nd, type = "parameter", FUN = c95)

par(mar = c(4.5, 4, 0.5, 0.5))
plot2d(p.no ~ age, data = nd, ylab = "participation",
  ylim = range(c(nd$p.no, nd$p.yes)), lty = c(2, 1, 2))
plot2d(p.yes ~ age, data = nd, col.lines = "blue", add = TRUE,
  lty = c(2, 1, 2))
legend("topright", c("foreign yes", "foreign no"), lwd = 1,
  col = c("blue", "black"))
```
The plot nicely depicts the nonlinear effect of variable `age` for the two levels
of `foreign`.

## Models for Count Data {#countreg}

This example is taken from @bamlss:Zeileis+Kleiber+Jackman:2008. The application is about
modeling the demand for medical care by elderly and was first analyzed by @bamlss:Deb+Trivedi:1997. The data can be downloaded on loaded into R with
```{r}
download.file(
  "https://www.jstatsoft.org/index.php/jss/article/downloadSuppFile/v027i08/DebTrivedi.rda.zip",
  "DebTrivedi.rda.zip"
)
unzip("DebTrivedi.rda.zip")
load("DebTrivedi.rda")
print(head(DebTrivedi))
```
The response variable in this data is the number of physician office visits, variable `ofp`. A
histogram of the count data response can be plotted with
```{r, eval=FALSE}
plot(table(DebTrivedi$ofp),
  xlab = "Number of physician office visits",
  ylab = "Frequency")
```
```{r, fig.width = 5, fig.height = 5, fig.align = "center", dev = "png", echo = FALSE, dev = "png", results = 'hide', message=FALSE}
par(mar = c(4.5, 4, 0.5, 0.5))
plot(table(DebTrivedi$ofp),
  xlab = "Number of physician office visits",
  ylab = "Frequency")
```
which shows very large counts and also a large number of zero counts. Our first model is a
Poisson regression, which can be estimated with
```{r, echo=FALSE, message=FALSE, results='hide'}
if(!file.exists("figures/Poisson.rda")) {
  f <- ofp ~ hosp + health + numchron + gender + school + privins
  set.seed(123)
  b1 <- bamlss(f, family = "poisson", data = DebTrivedi,
    n.iter = 12000, burnin = 2000, thin = 10)
  save(b1, file = "figures/Poisson1.rda")
} else {
  load("figures/Poisson1.rda")
}
```
```{r, eval=FALSE}
## Set the seed for reproducibly.
set.seed(123)

## Model formula.
f <- ofp ~ hosp + health + numchron + gender + school + privins

## Estimate model.
b1 <- bamlss(f, family = "poisson", data = DebTrivedi,
  n.iter = 12000, burnin = 2000, thin = 10)
```
The model summary is shown by
```{r}
summary(b1)
```
which shows "significant" effects for all covariates, since there are no zeros within
the 95% credible intervals. We can use randomized quantile residuals [@bamlss:Dunn+Gordon:1996]
to evaluate how good the models fits to the data.
```{r, eval = FALSE}
plot(b1, which = c("hist-resid", "qq-resid"))
```
```{r, fig.width = 8, fig.height = 4, fig.align = "center", echo = FALSE, dev = "png", echo=FALSE}
par(mfrow = c(1, 2))
plot(b1, which = c("hist-resid", "qq-resid"), spar = FALSE)
```
Clearly, the plots shows that the model performance is not very good at the tails of the data,
this might be caused by the large amount of zero counts in the data, which is not accounted for
using the Poisson distribution.

Therefore, another possible candidate for the response distribution is the
zero-inflated negative binomial distribution, which is implemented in the _gamlss_ package
[@bamlss:Stasinopoulos+Rigby:2018] in the function `ZINBI`. The family has 3 parameters `mu`,
`sigma` and `nu`. In this example we model distributional parameters `mu` and `sigma` in terms of
covariates by setting up the model formula with
```{r}
f <- list(
  ofp ~ hosp + health + numchron + gender + school + privins,
  sigma ~ hosp + health + numchron + gender + school + privins,
  nu ~ 1
)
```
Note, for parameter `nu` an intercept only model would also be the default if the specification
is omitted in the model formula. The model is estimated with (note, this can take some time)
```{r, echo=FALSE, message=FALSE, results='hide'}
library("gamlss")
if(!file.exists("figures/Poisson2.rda")) {
  set.seed(123)
  b2 <- bamlss(f, family = ZINBI, data = DebTrivedi,
    n.iter = 12000, burnin = 2000, thin = 10)
  save(b2, file = "figures/Poisson2.rda")
} else {
  load("figures/Poisson2.rda")
}
```
```{r, eval=FALSE}
## Set the seed for reproducibly.
set.seed(123)

## Estimate model.
b2 <- bamlss(f, family = ZINBI, data = DebTrivedi,
  n.iter = 12000, burnin = 2000, thin = 10)
```
The model summary gives
```{r}
summary(b2)
```
and the corresponding randomized quantile residuals plots are created with
```{r, eval = FALSE}
plot(b2, which = c("hist-resid", "qq-resid"))
```
```{r, fig.width = 8, fig.height = 4, fig.align = "center", echo = FALSE, dev = "png", echo=FALSE}
par(mfrow = c(1, 2))
plot(b2, which = c("hist-resid", "qq-resid"), spar = FALSE)
```
The plots indicate a better model fit compared to the Poisson model, this is also indicated
by the much lower DIC.
```{r}
DIC(b1, b2)
```

## References

