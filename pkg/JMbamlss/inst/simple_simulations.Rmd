---
title: "Simple MJMs"
author: "Alex"
date: "4/13/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MFPCA)
library(tidyverse)
library(Matrix)
library(mvtnorm)
library(survival)
library(bamlss)
setwd("..")


# Data Generation
source("R/simMultiJM.R")
source("R/preprocessing.R")

# Helperfunction PCRE
source("R/eval_mfun.R")
source("R/pcre_smooth.R")

# Family Construction
source("R/mjm_bamlss.R")
source("R/MJM_transform.R")
source("R/opt_MJM.R")
source("R/opt_updating.R")
source("R/MJM_mcmc.R")
source("R/mcmc_proposing.R")
source("R/survint.R")

# Load models and other objects
load("inst/objects/find_sim_data.Rdata")
d_mfpc <- d_indepri
load("inst/objects/indepri_models.Rdata")
load("inst/objects/indeprirs_models.Rdata")
load("inst/objects/indeprirs_mfpca.Rdata")
load("inst/objects/indeprirs_pcre_models.Rdata")
```

## Idea

Start with simple simulation scenarios for a proof of concept. In particular, start with a multivariate joint model, where the intra-subject association of the longitudinal part is induced only by a random intercept. Then expand it further to more complex scenarios.

The proof of concept follows the outline:

- Data generation
- Data preparation
- Model formula
- Model fit
- Sampling statistics

## Random Intercept Model

### Model Specification

The following model is specified
\begin{equation}
h_i(t) = \text{exp}\{\eta_{\lambda i}(t) + \eta_{\gamma i}(x) + \eta_{\alpha_{1}i}\cdot\eta_{\mu_{1}i}(t,x)+\eta_{\alpha_{2}i}\cdot\eta_{\mu_{2}i}(t,x)\}\\
y_{ijk} = \eta_{\mu_{k}i} (t_{ijk}) + \epsilon_{ijk},\quad k = 1,2\\
\epsilon_{ijk}\overset{\text{iid}}{\sim} N(0, \exp\{\log (0.6)\}^2)
\end{equation}
with
\begin{align}
\eta_{\lambda i}(t) &= 1.37\cdot t^{0.37}\\
\eta_{\gamma i} &= -5.8 + 0.48\cdot x_i\\
\eta_{\alpha_{1} i} &= 0.64\\
\eta_{\mu_{1} i}(t,x) &= 2.13 + 0.24\cdot t - 0.25\cdot x_i - 0.5\cdot t\cdot x_i + b_{1i}\\
\eta_{\alpha_{2} i} &= -0.64\\
\eta_{\mu_{2} i}(t,x) &= 2.13 + 0.24\cdot t - 0.25\cdot x_i - 0.5\cdot t\cdot x_i + b_{2i}\\
\begin{pmatrix} b_{1i} \\ b_{2i}\end{pmatrix} &\sim N\left(\begin{pmatrix}0 \\ 0\end{pmatrix}, \begin{pmatrix}0.68 & 0 \\ 0 & 0.68 \end{pmatrix}\right)
\end{align}
where $i = 1,..., 150$, $t\in[0,25]$, and $x_i$ is a binary covariate.

Note that the longitudinal trajectories are the same except for the random intercept, but the association parameters have opposite signs.

The true baseline hazard (with gamma intercept) is given by
```{r, fig.height=4}
curve(1.37*x^0.37-5.8)
```


### Data Generation

```{r, fig.height=4, attr.source='style="max-height: 300px;"'}
# Generate data with independent random intercepts
d_indepri <- simMultiJM(nsub = 150, times = seq(0, 25, by = 0.25), 
                        probmiss = 0.75, maxfac = 1.5,
                        nmark = 2, param_assoc = TRUE, M = NULL, 
                        FPC_bases = NULL, FPC_evals = NULL, mfpc_args = NULL,
                        re_cov_mat = matrix(c(0.68, 0, 0, 0.68), ncol = 2), 
                        ncovar = 2,
                        lambda = function(t, x) {
                          1.37 * t^(0.37)
                        },
                        gamma = function(x) {
                          - 5.8 + 0.48*x[, 3]
                        },
                        alpha = list(function(t, x) {
                          0.64 + 0*t
                        }, function(t, x) {
                          -0.64 + 0*t
                        }),
                        mu = list(function(t, x, r){
                          2.13 + 0.24*t - 0.25*x[, 3] - 0.05*t*x[, 3] + 
                            r[, 1]
                        }, function(t, x, r){
                          2.13 + 0.24*t - 0.25*x[, 3] - 0.05*t*x[, 3] + 
                            r[, 2]
                        }),
                        sigma = function(t, x) {
                          log(0.6) + 0*t
                        }, 
                        tmax = NULL, seed = 1808, 
                        full = TRUE, file = NULL)

```

```{r, echo=FALSE}

ggplot(d_indepri$data, aes(x = obstime, y = y, color = id)) +
  geom_point() +
  geom_line(aes(y = mu)) +
  facet_grid(~marker) +
  theme(legend.position = "none")

ggplot(d_indepri$data, aes(x = id, y = survtime, color = factor(event))) +
  geom_point()
```


### Model Fit

#### Model using independent random effects
Specify and fit the model using a random intercept per marker
```{r, eval=FALSE}
f_indepri_byre <- list(
  Surv2(survtime, event, obs = y) ~ -1 + s(survtime, k = 10),
  gamma ~ 1 + x3,
  mu ~ -1 + marker + obstime:marker + x3:marker + obstime:marker:x3 +
    s(id, by = marker, bs = "re"),
sigma ~ -1 + marker,
alpha ~ -1 + marker
)

set.seed(1808)

b_indepri_byre <- bamlss(f_indepri_byre, family = mjm_bamlss, 
                          data = d_indepri$data, timevar = "obstime",
                          maxit = 1000, verbose_sampler = TRUE)
```

Baseline hazard is estimated too smoothly and is not on the right scale.
```{r, fig.heigt=4, comment='', attr.output='style="max-height: 400px;"'}
plot(b_indepri_byre, model = "lambda", ask = FALSE)
summary(b_indepri_byre)
```

The following list compares the estimates (sample mean) with the true parameters.
```{r, echo=FALSE}
sumry <- summary(b_indepri_byre)$model.matrix
cat("Gamma: 0.48\n")
sumry$gamma[2, 1]
cat("Alpha1: 0.64, Alpha2: -0.64")
c(sumry$alpha[1, 1], sumry$alpha[2, 1])
cat("Mu1/Mu2: 2.13, 0.24, -0.25, -0.5")
c(sumry$mu[1, 1], sumry$mu[2, 1])
c(sumry$mu[3, 1], sumry$mu[4, 1])
c(sumry$mu[5, 1], sumry$mu[6, 1])
c(sumry$mu[7, 1], sumry$mu[8, 1])
```
This shows reasonable estimates for the relatively small data set.

The longitudinal data fit also seems ok (the dashed line corresponds to the fit and the solid line to the true longitudinal trajectory). Here a sample of five randomly drawn observations.

```{r, echo=FALSE}
set.seed(1808)
ids <- sample(unique(d_indepri$data_short[which(
  d_indepri$data_short$survtime < 25.1 &d_indepri$data_short$survtime > 20), 
  "id"]), 5, replace = FALSE)

ggplot(data = d_indepri$data %>% 
                   mutate(fit_twopcre = b_indepri_byre$fitted.values$mu) %>% 
                   filter(id %in% ids), aes(x = obstime, color = id)) +
  geom_point(aes(y = y), size = 1.3) +
  geom_line(aes(y = fit_twopcre), linetype = "dashed") +
  geom_line(aes(y = mu)) +
  facet_grid(~marker)
```


Acceptance probabilities also look ok.

```{r, echo=FALSE}
acc <- grep("accepted", colnames(b_indepri_byre$samples[[1]]))
summary(b_indepri_byre$samples[[1]][, acc])
plot(b_indepri_byre, model = "alpha", which = "samples", ask = FALSE)
```


#### Model using independent random intercepts specified using pcre-term
Create an appropriate FPC basis using constant functions as first and second fPCs
```{r}
# Use an appropriate FPC basis
seq <- seq(0, 25, by = 0.25)
fund <- eFun(argvals = seq, M = 2, type = "Poly")
fpc_base_one <- multiFunData(
  funData(argvals = seq,
          X = matrix(c(fund@X[1, ],
                       rep(0, length(seq))),
                     nrow = 2, byrow = TRUE)),
  funData(argvals = seq,
          X = matrix(c(rep(0, length(seq)),
                       fund@X[1, ]),
                     nrow = 2, byrow = TRUE))
)
plot(fpc_base_one)
```

Choosing the eigenvalues for weighting the functional principal components (maybe computationally advantageous?) by the following logic: From the data simulation we know that $b_{ki} \sim N(0, 68)$, so when we understand the random effect as a constant function, $Var(b_{ki}\cdot 1) = 0.68$ at each time $t$. Now, with normalized constant function as basis, we would still like to achieve the same point-wise variance and therefore introduce a different parameterization with random score $r_k \sim N(0, \sigma^2)$. We want $Var(r_k \cdot 0.2) \overset{!}{=} 0.68$. So we might take
\begin{equation}
\sigma^2 = Var(r_k) = \frac{0.68}{0.2^2} = 17
\end{equation}
as eigenvalues. Weighting the eigenfunctions with $\sqrt{17}$ should then give standard normal distributed random effects $r^*_{ki}$:
\begin{align*}
Var(r^{*}_{ki}\cdot 0.2 \cdot \sqrt(17)) &\overset{!}{=} 0.68 \\
\Rightarrow Var(r^{*}) &= \frac{0.68}{(0.2^2\cdot 17)} = 1
\end{align*}
```{r, eval=FALSE}
# Create necessary object to include in the model
mfpca_indepri <- list(
  functions = fpc_base_one,
  values = c(17, 17)
)

# Attach the FPCS
d_indepri_data <- attach_wfpc(mfpca_indepri, d_indepri$data)

# New model formula
f_indepri_twopcre <- list(
  Surv2(survtime, event, obs = y) ~ -1 + s(survtime, k = 10),
  gamma ~ 1 + x3,
  mu ~ -1 + marker + obstime:marker + x3:marker + obstime:marker:x3 +
    s(id, wfpc.1, bs = "unc_pcre",
      xt = list("mfpc" = list(functions = extractObs(fpc_base_one, 1),
                              values = c(17)))) +
    s(id, wfpc.2, bs = "unc_pcre",
      xt = list("mfpc" = list(functions = extractObs(fpc_base_one, 2),
                              values = c(17)))),
  sigma ~ -1 + marker,
  alpha ~ -1 + marker
)

set.seed(1808)
b_indepri_twopcre <- bamlss(f_indepri_twopcre, family = mjm_bamlss, 
                            data = d_indepri_data, timevar = "obstime",
                            maxit = 1000, verbose_sampler = TRUE)
```

The resulting models are actually equal:
```{r}
all.equal(b_indepri_byre$fitted.values$mu, b_indepri_twopcre$fitted.values$mu)
```

## Random Intercept / Random Slope Model

### Model Specification

Only the longitudinal predictors $\eta_{\mu_1i}(t,x)$ and $\eta_{\mu_2i}(t,x)$ are adjusted by including a random slope in the model so that
\begin{align}
\eta_{\mu_{1} i}(t,x) &= 2.13 + 0.24\cdot t - 0.25\cdot x_i - 0.5\cdot t\cdot x_i + b_{1i} + b_{2i}\cdot t\\
\eta_{\mu_{2} i}(t,x) &= 2.13 + 0.24\cdot t - 0.25\cdot x_i - 0.5\cdot t\cdot x_i + b_{3i} + b_{4i}\cdot t\\
\begin{pmatrix} b_{1i} \\ b_{2i}\\ b_{3i} \\ b_{4i} \end{pmatrix} &\sim N\left(\begin{pmatrix}0 \\ 0 \\ 0 \\ 0\end{pmatrix}, \begin{pmatrix}0.68 & & & \\  & 0.28 & & \\ & & 0.68 & \\ & & & 0.28 \end{pmatrix}\right).
\end{align}


### Data Generation

```{r, fig.height=4, attr.source='style="max-height: 300px;"'}
# Generate data with independent RI+RS
d_indeprirs <- simMultiJM(nsub = 150, times = seq(0, 25, by = 0.25), 
                          probmiss = 0.75, maxfac = 1.5,
                          nmark = 2, param_assoc = TRUE, M = NULL, 
                          FPC_bases = NULL, FPC_evals = NULL, mfpc_args = NULL,
                          re_cov_mat = matrix(c(0.68, 0, 0, 0,
                                                0, 0.28, 0, 0,
                                                0, 0, 0.68, 0,
                                                0, 0, 0, 0.28), ncol = 4), 
                          ncovar = 2,
                          lambda = function(t, x) {
                            1.37 * t^(0.37)
                          },
                          gamma = function(x) {
                            - 5.8 + 0.48*x[, 3]
                          },
                          alpha = list(function(t, x) {
                            0.64 + 0*t
                          }, function(t, x) {
                            -0.64 + 0*t
                          }),
                          mu = list(function(t, x, r){
                            2.13 + 0.24*t - 0.25*x[, 3] - 0.05*t*x[, 3] + 
                              r[, 1] + r[, 2]*t
                          }, function(t, x, r){
                            2.13 + 0.24*t - 0.25*x[, 3] - 0.05*t*x[, 3] + 
                              r[, 3] + r[, 4]*t
                          }),
                          sigma = function(t, x) {
                            log(0.6) + 0*t
                          }, 
                          tmax = NULL, seed = 1808, 
                          full = TRUE, file = NULL)

```

```{r, echo=FALSE}

ggplot(d_indeprirs$data, aes(x = obstime, y = y, color = id)) +
  geom_point() +
  geom_line(aes(y = mu)) +
  facet_grid(~marker) +
  theme(legend.position = "none")

ggplot(d_indeprirs$data, aes(x = id, y = survtime, color = factor(event))) +
  geom_point()
```


### Model Fit

#### Model using independent random effects
Specify and fit the model using RI+RS per marker

```{r, eval=FALSE}
f_indeprirs_re <- list(
  Surv2(survtime, event, obs = y) ~ -1 + s(survtime, k = 10),
  gamma ~ 1 + x3,
  mu ~ -1 + marker + obstime:marker + x3:marker + obstime:marker:x3 +
    s(id, marker, bs = "re") + s(id, marker, obstime, bs = "re"),
  sigma ~ -1 + marker,
  alpha ~ -1 + marker
)

set.seed(1808)

b_indeprirs_re <- bamlss(f_indeprirs_re, family = mjm_bamlss, 
                         data = d_indeprirs$data, timevar = "obstime",
                         maxit = 1000, verbose_sampler = TRUE)

```

Baseline hazard is estimated too smoothly.
```{r, fig.heigt=4, comment='', attr.output='style="max-height: 400px;"'}
plot(b_indeprirs_re, model = "lambda", ask = FALSE)
summary(b_indeprirs_re)
```

The following list compares the estimates (sample mean) with the true parameters.
```{r, echo=FALSE}
sumry <- summary(b_indeprirs_re)$model.matrix
cat("Gamma: 0.48\n")
sumry$gamma[2, 1]
cat("Alpha1: 0.64, Alpha2: -0.64")
c(sumry$alpha[1, 1], sumry$alpha[2, 1])
cat("Mu1/Mu2: 2.13, 0.24, -0.25, -0.5")
c(sumry$mu[1, 1], sumry$mu[2, 1])
c(sumry$mu[3, 1], sumry$mu[4, 1])
c(sumry$mu[5, 1], sumry$mu[6, 1])
c(sumry$mu[7, 1], sumry$mu[8, 1])
```

The longitudinal data fit also seems ok (the dashed line corresponds to the fit and the solid line to the true longitudinal trajectory). Here a sample of five randomly drawn observations.

```{r, echo=FALSE}
set.seed(1808)
ids <- sample(unique(d_indeprirs$data_short[which(
  d_indeprirs$data_short$survtime < 25.1 &d_indeprirs$data_short$survtime > 20), 
  "id"]), 5, replace = FALSE)

ggplot(data = d_indeprirs$data %>% 
                   mutate(fit_twopcre = b_indeprirs_re$fitted.values$mu) %>% 
                   filter(id %in% ids), aes(x = obstime, color = id)) +
  geom_point(aes(y = y), size = 1.3) +
  geom_line(aes(y = fit_twopcre), linetype = "dashed") +
  geom_line(aes(y = mu)) +
  facet_grid(~marker)
```

Acceptance probabilities also look ok.

```{r, echo=FALSE}
acc <- grep("accepted", colnames(b_indeprirs_re$samples[[1]]))
summary(b_indeprirs_re$samples[[1]][, acc])
plot(b_indeprirs_re, model = "alpha", which = "samples", ask = FALSE)
```


#### Model using independent RI+RS specified using pcre-term
Creating an appropriate FPC basis is not as straigtforward as with the simple RI model in that we cannot simply use the corresponding polynomials as in
```{r}
fpc_base_two <- multiFunData(
  funData(argvals = seq,
          X = matrix(c(fund@X[1, ],
                       rep(0, length(seq)),
                       fund@X[2, ],
                       rep(0, length(seq))),
                     nrow = 4, byrow = TRUE)),
  funData(argvals = seq,
          X = matrix(c(rep(0, length(seq)),
                       fund@X[1, ],
                       rep(0, length(seq)),
                       fund@X[2, ]),
                     nrow = 4, byrow = TRUE))
)
plot(fpc_base_two)
```

The reason is the orthonormality of the FPCs: This would e.g. mean that the linear FPC needed to be follow a sum-to-zero constraint so that its root is at the center of the interval. Consider rewriting the model
\begin{align*}
y_i(t) &= \mu_i(t) + b_{0i} + b_{1i}\cdot t\\
&= \mu_i(t) + b_{0i} + (t- 12.5)b_{1i} + 12.5b_{1i}\\
&= \mu_i(t) + \underbrace{b_{0i} +  12.5b_{1i}}_{b_{0i}^*} + (t- 12.5)b_{1i}\\
&= \mu_i(t) + b_{0i}^* + (t- 12.5)b_{1i}
\end{align*}
which introduces correlation between $b_{0i}^*$ and $b_{1i}$, which would be neglected by modeling using these FPCs. A practical solution to finding appropriate FPCs is to use the random effects structure of the data simulation and simulate data to use in an MFPCA.

```{r, eval = FALSE}
# Use MFPCA to get a functioning FPC basis for the covariance operator
n <- 100000
b <- mvtnorm::rmvnorm(n = n, mean = c(0,0,0,0), 
                      sigma = diag(c(0.68, 0.28, 0.68, 0.28)))

mfun <- multiFunData(
  funData(argvals = seq,
          X = (b[, 1:2] %*% matrix(c(rep(1, length(seq)), seq),
                                   byrow = TRUE, ncol = length(seq)))),
  funData(argvals = seq,
          X = (b[, 3:4] %*% matrix(c(rep(1, length(seq)), seq),
                                   byrow = TRUE, ncol = length(seq))))
)
mfpca_est2 <- MFPCA(mFData = mfun, M = 4, 
                    uniExpansions = list(list(type = "uFPCA"),
                                         list(type = "uFPCA")))
mfpca_est4 <- MFPCA(mFData = mfun, M = 4, 
                   uniExpansions = list(list(type = "uFPCA", npc = 2),
                                        list(type = "uFPCA", npc = 2)))

```
```{r}
plot(mfpca_est2$functions, col = c("red", "blue"))
plot(mfpca_est4$functions, col = c("red", "blue", "green", "purple"))
mfpca_est2$values
mfpca_est4$values
```

However, it makes a difference whether to include two or four FPC basis functions as only in the latter case the model converges and gives reasonable acceptance rates

```{r, eval=FALSE}
# Different formulas for different FPC basis
f_indeprirs_pcre_est2 <- list(
  Surv2(survtime, event, obs = y) ~ -1 + s(survtime, k = 10),
  gamma ~ 1 + x3,
  mu ~ -1 + marker + obstime:marker + x3:marker + obstime:marker:x3 +
    s(id, wfpc.1, wfpc.2, bs = "unc_pcre",
      xt = list("mfpc" = mfpca_est2)),
  sigma ~ -1 + marker,
  alpha ~ -1 + marker
)

f_indeprirs_pcre_est4 <- list(
  Surv2(survtime, event, obs = y) ~ -1 + s(survtime, k = 10),
  gamma ~ 1 + x3,
  mu ~ -1 + marker + obstime:marker + x3:marker + obstime:marker:x3 +
    s(id, wfpc.1, wfpc.2, wfpc.3, wfpc.4, bs = "unc_pcre",
      xt = list("mfpc" = mfpca_est4)),
  sigma ~ -1 + marker,
  alpha ~ -1 + marker
)

set.seed(1808)
b_indeprirs_pcre_est2 <- bamlss(f_indeprirs_pcre_est2, family = mjm_bamlss, 
                                data = d_indeprirs_data_est2,
                                timevar = "obstime",
                                maxit = 1000, verbose_sampler = TRUE)

set.seed(1808)
b_indeprirs_pcre_est4 <- bamlss(f_indeprirs_pcre_est4, family = mjm_bamlss, 
                                data = d_indeprirs_data_est4, 
                                timevar = "obstime",
                                maxit = 1000, verbose_sampler = TRUE)

```


```{r}
b_indeprirs_pcre_est2$model.stats$optimizer$converged
b_indeprirs_pcre_est4$model.stats$optimizer$converged
acc2 <- grep("accepted", colnames(b_indeprirs_pcre_est2$samples[[1]]))
summary(b_indeprirs_pcre_est2$samples[[1]][, acc2])
acc4 <- grep("accepted", colnames(b_indeprirs_pcre_est4$samples[[1]]))
summary(b_indeprirs_pcre_est4$samples[[1]][, acc4])
```
```{r, echo=FALSE}
ggplot(data = d_indeprirs$data %>% 
                   mutate(fit_fourpcre = b_indeprirs_pcre_est4$fitted.values$mu) %>% 
                   filter(id %in% ids), aes(x = obstime, color = id)) +
  geom_point(aes(y = y), size = 1.3) +
  geom_line(aes(y = fit_fourpcre), linetype = "dashed") +
  geom_line(aes(y = mu)) +
  facet_grid(~marker)

```


## Model using MFPCs

### Model Specification

The longitudinal predictors $\eta_{\mu_1i}(t,x)$ and $\eta_{\mu_2i}(t,x)$ are adjusted so that the longitudinal trajectories become highly individual specific. We generate the random effect structure by including 8 functional principal components based on polynomials, excluding degree 1:

```{r}
mfpca <- create_true_MFPCA(M = 8, nmarker = 2, argvals = seq(0, 25, by = 0.25),
                           type = "split", eFunType = "PolyHigh",
                           ignoreDeg = 1, eValType = "linear",
                           eValScale = 1, evals = c(80:73))
plot(mfpca$functions)
```

To get a reasonable event distribution, the baseline hazard has to be adjusted.

### Data Generation
```{r}
# Generate data with MFPC basis
d_mfpc <- simMultiJM(nsub = 150, times = seq(0, 25, by = 0.25), 
                        probmiss = 0.75, maxfac = 2,
                        nmark = 2, param_assoc = FALSE, M = 8, 
                        FPC_bases = NULL, 
                        FPC_evals = c(80:73),
                        mfpc_args = list(type = "split", eFunType = "PolyHigh",
                                         ignoreDeg = 1, eValType = "linear",
                                         eValScale = 1),
                        ncovar = 2,
                        lambda = function(t, x) {
                          1.6 * t^(0.6)
                        },
                        gamma = function(x) {
                          - 10 + 0.48*x[, 3]
                        },
                        alpha = list(function(t, x) {
                          0.64 + 0*t
                        }, function(t, x) {
                          -0.64 + 0*t
                        }),
                        mu = list(function(t, x, r){
                          2 + 0.24*t - 0.25*x[, 3] - 0.05*t*x[, 3]
                        }, function(t, x, r){
                          2 + 0.24*t - 0.25*x[, 3] - 0.05*t*x[, 3]
                        }),
                        sigma = function(t, x) {
                          log(0.6) + 0*t
                        }, 
                        tmax = NULL, seed = 1808, 
                        full = TRUE, file = NULL)
```

```{r, echo=FALSE}
ggplot(d_mfpc$data, aes(x = obstime, y = y, color = id)) +
  geom_line() +
  facet_grid(~marker) +
  theme(legend.position = "none")

ggplot(d_mfpc$data, aes(x = id, y = survtime, color = factor(event))) +
  geom_point()
```

However, when this model is fit using the PCRE term, the model fit shows convergence problems. Up to optimizing iteration 960, the log-likelihood increases but afterwards, it decreases again.

```{r, eval=FALSE}
f <- list(
  Surv2(survtime, event, obs = y) ~ -1 + s(survtime, k = 10, bs = "ps"),
  gamma ~ 1 + x3,
  mu ~ -1 + marker + obstime:marker + x3:marker + 
    s(id, wfpc.1, wfpc.2, wfpc.3, wfpc.4, wfpc.5, wfpc.6, wfpc.7, wfpc.8,
      bs = "unc_pcre", xt = list("mfpc" = mfpca)),
  sigma ~ -1 + marker,
  alpha ~ -1 + marker
)
set.seed(1808)
b_sim1 <- bamlss(f, family = mjm_bamlss, data = d_indepri$data, 
                timevar = "obstime", maxit = 1200, verbose_sampler = TRUE)
```

```{r, echo=FALSE, comment='', attr.output='style="max-height: 400px;"'}
cat(readLines("../find_sim200422.txt"), sep = "\n")
```

